{"cells":[{"cell_type":"markdown","source":["# Set-up"],"metadata":{"id":"CfaTkNbAbMhe"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qdiRkyDYQ5HT","executionInfo":{"status":"ok","timestamp":1668826029274,"user_tz":300,"elapsed":1430,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"8a589972-26ca-4c1f-a647-7029971638f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BEur8cLCR1Zk"},"outputs":[],"source":["# Import required packages\n","from __future__ import absolute_import, division, print_function, unicode_literals\n","from tqdm.notebook import tqdm    # for fancy progress bar\n","from PIL import Image             # PILLOW for working with images\n","import pandas as pd               # pandas for working and manipulating data\n","import os                         # for performing OS realted operations\n","import numpy as np                # for working with numerical arrays\n","import matplotlib.pyplot as plt   # for matrix plots\n","import collections                # for working with different container datatypes\n","from pprint import pprint         # Pretty Printer for prinitng results differently\n","\n","#Import models for NN training and loading dataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import train_test_split\n","\n","\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, LSTM, Input, Embedding, Bidirectional, GRU, Dropout, Attention\n","from tensorflow.keras.optimizers import Adam\n","\n"]},{"cell_type":"markdown","source":["# Data Loading and Pre Processing"],"metadata":{"id":"4_ICLcP1E4AE"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["0b6d04620ec24cc99c32afc0f3880823","9143a870dec54e93806b93b2666f4452","e12422d084b44487828d727d060ad3b8","67db9a14ece54b5bb2c352766503ff1d","e3051eefa2bc4e70a768f26928976d27","ec0035e7a94c4d0789d7a6ad5d5aee28","70416de52849433eaee1c1489138dbec","56491b38baf04a2a87bf175b38025740","2c36714bbd50490eb06229599d1ac36e","118626f057c54accbb6f67b0a8be800e","e1475f49197f4306bd27b1e34904998e"]},"id":"7NGojpH_R1Zl","outputId":"ef919e27-b81a-4b4b-de80-0fba23dfc65d","executionInfo":{"status":"ok","timestamp":1668826153707,"user_tz":300,"elapsed":115586,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/7627 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b6d04620ec24cc99c32afc0f3880823"}},"metadata":{}}],"source":["# preprocess image data\n","\n","def load_image(file):\n","    try:\n","        image = Image.open(                       # Try to open the image for the passed index from the training file\n","            file\n","        ).convert('LA').resize((64, 64))          # Resize iamges to a constant (256,256) size and convert to 8-bit greyscale image with alphas\n","        arr = np.array(image)                     # Create an array of image\n","    except:\n","        arr = np.zeros((64, 64, 2))               # If it throws an error,  Create an empty (zero) array of size (64,64,2)\n","    return arr                                    # return the array in either case.\n","\n","# Create dataframe to hold train and test data\n","xy_train_df = pd.read_csv('/content/drive/MyDrive/cisc/A4_5/data/train_xy.csv')\n","x_test_df = pd.read_csv('/content/drive/MyDrive/cisc/A4_5/data/test_x.csv')\n","\n","# Create a new column in dataframe to change path for loading images (since the path is different)\n","xy_train_df['loadpath'] = '/content/drive/MyDrive/cisc/A4_5/data/' + xy_train_df.image\n","\n","# Load images from the corresponding indexes in dataframe\n","x_image = np.array([load_image(i) for i in tqdm(xy_train_df.loadpath)])\n","\n","# Load the Summary/caption of each image from the dataframe (force convert some of the non-string cells to string)\n","x_text = xy_train_df.summary.astype('str')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":286},"id":"Ayqfe7rQS0Mk","outputId":"afb7dd28-2ecc-46b6-f9ec-872299b98920","executionInfo":{"status":"ok","timestamp":1668826654223,"user_tz":300,"elapsed":634,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f13f7d01cd0>"]},"metadata":{},"execution_count":10},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["# check image loading\n","plt.imshow(x_image[12, :, :, 0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1z3FEfYsR1Zm","outputId":"fed1f677-9f68-491a-b677-ffc6ac604530","executionInfo":{"status":"ok","timestamp":1668826154333,"user_tz":300,"elapsed":236,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["unique values for price category 3 [1 0 2]\n","unique values for type category 24 [ 1 17 22 10 18 20  5  2  8  4 23 13 15 16 14 11 19  0 21  3  6 12  7  9]\n"]}],"source":["# Create labels from trainnig dataset\n","y_price = xy_train_df.price\n","y_type = xy_train_df.type.astype('category').cat.codes    # Convert 'types' to numerical encodings\n","\n","#Check for unique values and print them\n","len_price = len(y_price.unique())                         # Find total no. of unique values for price\n","len_type = len(y_type.unique())                           # Find total no. of unique values for type\n","print('unique values for price category', len_price, y_price.unique())\n","print('unique values for type category', len_type, y_type.unique())\n","\n","\n","# Create a training and validation split from the imported Training images and text\n","x_tr_image, x_vl_image, x_tr_text, x_vl_text, y_tr_price, y_vl_price, y_tr_type, y_vl_type = train_test_split(\n","    x_image,\n","    x_text,\n","    y_price,\n","    y_type,\n","    test_size=0.2)    # Use 20% of the dataset for test (validation) split\n","\n","# # Print shapes of new dataset split to verify the number of images\n","\n","# print(np.shape(x_tr_image))\n","# print(np.shape(x_vl_image))\n","# print(np.shape(y_tr_price))\n","# print(np.shape(y_vl_price))\n","# print(np.shape(y_tr_type))\n","# print(np.shape(y_vl_type))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xh70MnCDR1Zm"},"outputs":[],"source":["# Preprocess text data\n","vocab_size = 40000\n","max_len = 100\n","\n","# build vocabulary from training set\n","tokenizer = Tokenizer(num_words=vocab_size)             # Create a token holder object of size 40k\n","tokenizer.fit_on_texts(x_tr_text)                       # Create an index for vocabulary based on frequency of each word in the text\n","\n","\n","# Define a function to Preprocess and create padded text data, ensures that all the data is of same length and adds required padding\n","def _preprocess(list_of_text):\n","    return pad_sequences(                               # Return same legth padded sequences\n","        tokenizer.texts_to_sequences(list_of_text),     # Transform the text embeddings in the vocab into a sequence of integrers\n","        maxlen=max_len,                                 # Maximum legth of the text should be 100\n","        padding='post',                                 # Determines that padding be added at the end of strings\n","    )\n","\n","\n","# padding is done inside:\n","x_tr_text_id = _preprocess(x_tr_text)\n","x_vl_text_id = _preprocess(x_vl_text)\n","\n","# print(x_tr_text_id.shape)\n","# print(x_vl_text_id.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p5E5zYSiR1Zm","outputId":"b5501e93-e908-49a2-86fc-1afd425046f1","executionInfo":{"status":"ok","timestamp":1668826155222,"user_tz":300,"elapsed":13,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["['vivre montréal sous la tente à la jonction des quartiers typiques '\n"," \"montréalais homa village et plateau vous vous situerez à l'entrée du pont \"\n"," \"jacques cartier la terrasse bénéficie d'une intimité presque absolue \"\n"," \"imaginez vous pourriez y dormir par ces beaux soirs d'été un bbq est \"\n"," 'disponible sur la terrasse',\n"," 'beautiful and spacious studio in nouvel hôtel spa for 4 people maximum '\n"," 'ideally located in the heart of downtown montreal 1 kingsize bed and 1 sofa '\n"," 'bed hair dryer oven dishwasher coffee machine oven sports room and laundry '\n"," 'service are at your disposal sheets and towels will be provided please note '\n"," 'that check in is between 3pm and 9pm and check out until 12pm for more '\n"," 'information please read the detailed description below',\n"," 'chambre dans une colocs de 3 chambres vous serez donc avec 2 autres '\n"," \"personnes de 22 et 24 ans l'appartement se trouve dans un bloc de 5 \"\n"," 'appartements qui se partagent la terrasse ambiance très convivial pour '\n"," \"rencontrer de nouvelles personnes l'appartement dispose de son salon avec \"\n"," 'vidéo projecteur cuisine avec lave vaisselle et four etc et une salle de '\n"," 'bain tout cela à partager avec mes 2 colocs à peine 5 min à pied du metro '\n"," 'berri et du metro baudry en plein dans le village',\n"," 'this is an ideal place for a few days stay amazing location just steps to a '\n"," 'bus stop and the metro station only a few minutes walk to some of the best '\n"," 'restaurants and bars in montreal easy check in simple room with a small '\n"," 'kitchen includes coffee maker dishes and silverware and electric stovetop '\n"," 'burner we do not provide shampoo body wash hand face towels please bring '\n"," 'yours if you require them',\n"," '3 1 2 complet toute inclus avec laveuse sécheuse']\n"]}],"source":["pprint(tokenizer.sequences_to_texts(x_tr_text_id[:5]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"75tmwBWAR1Zm","outputId":"6d85c45d-994c-42bc-a6d1-1399d798553e","executionInfo":{"status":"ok","timestamp":1668826155223,"user_tz":300,"elapsed":8,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["total words in the dictionary: 40000\n"]}],"source":["print('total words in the dictionary:', tokenizer.num_words)"]},{"cell_type":"markdown","source":["# Text Inputs: RNN Layers: Bi-LSTM + Bi-GRU"],"metadata":{"id":"W2Ld0Qh9kvPv"}},{"cell_type":"markdown","source":["This block focusses on predicting prices and types using text inputs only by implementing LSTMs.\n","\n","The aim is to see whether LSTMs are a good fit for given text dataset and if there is any scope of improvement.\n","\n","Trials Include changed Parameters for LSTM and exploring Bi_LSTM and Comparing with Bi-GRU.\n","\n"],"metadata":{"id":"3xxrsqUPk7M2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"eHUXFXX5R1Zm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668833530932,"user_tz":300,"elapsed":625,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"df08f1da-cb87-4030-a3c7-f8aa051938e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"lstm_model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_10 (InputLayer)       [(None, 100)]             0         \n","                                                                 \n"," embedding_6 (Embedding)     (None, 100, 100)          4000000   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 128)               117248    \n","                                                                 \n"," price (Dense)               (None, 3)                 387       \n","                                                                 \n","=================================================================\n","Total params: 4,117,635\n","Trainable params: 4,117,635\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["# Adding LSTM Layers to the model.\n","in_text = Input(batch_shape=(None, max_len))                # Creating input layer\n","e_layer = Embedding(tokenizer.num_words, 100)(in_text)      # Creating Embeddings layer\n","lstm_layer = LSTM(128)(e_layer)                             # Creating LSTM Layer with space dimensions = 128\n","\n","p_price = Dense(len_price, activation='softmax', name='price')(lstm_layer)\n","\n","model = keras.Model(in_text,p_price, name = 'lstm_model')\n","\n","model.compile(\n","    optimizer=Adam(),                         # Tried different optimmizers but Adam provided more reproduceable outputs\n","    loss='sparse_categorical_crossentropy',                    # Settings loss computation metrics for 'price'\n","    metrics=['SparseCategoricalAccuracy']                     # Metrics to use for evaluation during training\n",")\n","\n","model.summary()\n"]},{"cell_type":"code","source":["# Fit the model to begin training\n","history = model.fit(\n","    x = x_tr_text_id,\n","    y = y_tr_price,\n","    epochs = 10,                                    # Training for limited no. of epoch to save time on Free Colab version and prevent Max utilization\n","    batch_size = 64,\n","    validation_data = (x_vl_text_id, y_vl_price),\n","    validation_split = 0.2,\n","    verbose = 1\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n96h-weplCxC","executionInfo":{"status":"ok","timestamp":1668744555995,"user_tz":300,"elapsed":382229,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"8a0abb73-1393-4927-f2dc-93542d8ba792"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","96/96 [==============================] - 34s 347ms/step - loss: 0.7911 - sparse_categorical_accuracy: 0.6307 - val_loss: 0.7951 - val_sparse_categorical_accuracy: 0.6501\n","Epoch 2/10\n","96/96 [==============================] - 28s 292ms/step - loss: 0.8149 - sparse_categorical_accuracy: 0.6389 - val_loss: 0.8166 - val_sparse_categorical_accuracy: 0.6311\n","Epoch 3/10\n","96/96 [==============================] - 31s 319ms/step - loss: 0.8403 - sparse_categorical_accuracy: 0.6210 - val_loss: 0.8192 - val_sparse_categorical_accuracy: 0.6298\n","Epoch 4/10\n","96/96 [==============================] - 28s 291ms/step - loss: 0.8424 - sparse_categorical_accuracy: 0.6212 - val_loss: 0.8276 - val_sparse_categorical_accuracy: 0.6298\n","Epoch 5/10\n","96/96 [==============================] - 33s 344ms/step - loss: 0.8413 - sparse_categorical_accuracy: 0.6212 - val_loss: 0.8181 - val_sparse_categorical_accuracy: 0.6298\n","Epoch 6/10\n","96/96 [==============================] - 35s 360ms/step - loss: 0.8401 - sparse_categorical_accuracy: 0.6212 - val_loss: 0.8208 - val_sparse_categorical_accuracy: 0.6304\n","Epoch 7/10\n","96/96 [==============================] - 34s 349ms/step - loss: 0.8392 - sparse_categorical_accuracy: 0.6215 - val_loss: 0.8162 - val_sparse_categorical_accuracy: 0.6324\n","Epoch 8/10\n","96/96 [==============================] - 37s 384ms/step - loss: 0.8394 - sparse_categorical_accuracy: 0.6219 - val_loss: 0.8156 - val_sparse_categorical_accuracy: 0.6324\n","Epoch 9/10\n","96/96 [==============================] - 37s 389ms/step - loss: 0.8382 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.8154 - val_sparse_categorical_accuracy: 0.6337\n","Epoch 10/10\n","96/96 [==============================] - 31s 324ms/step - loss: 0.8388 - sparse_categorical_accuracy: 0.6220 - val_loss: 0.8205 - val_sparse_categorical_accuracy: 0.6278\n"]}]},{"cell_type":"markdown","source":["**Obervation**\n","\n","Results suggest further tuning could improve results.\n"],"metadata":{"id":"w2hhp5oZ86Pk"}},{"cell_type":"markdown","source":["**Next Trial: Bi-LSTM with different paramters:**\n","\n","* Added Bidirectionality\n","\n","* Changed Activation\n","\n","* Changed Layer sizes (dimensions)\n","\n","* Added Dense layers after LSTM\n","\n","* Bigger Batch size, lesser epochs to save time\n","\n","* MultiObjective: Predicting both **Price** and **Type**\n"],"metadata":{"id":"JgmW9ehG9HL1"}},{"cell_type":"code","source":["# Adding LSTM Layers to the model.\n","in_text = Input(batch_shape=(None, max_len))                # Creating input layer\n","e_layer = Embedding(tokenizer.num_words, 100)(in_text)      # Creating Embeddings layer\n","bi_lstm = Bidirectional(LSTM(64, activation = 'relu'))(e_layer)                  # Creating Bidirectional LSTM Layer\n","d_layer = Dense(32)(bi_lstm)\n","\n","# Same as before\n","p_price = Dense(len_price, activation='softmax', name='price')(d_layer)\n","p_type = Dense(len_type, activation='softmax', name='type')(d_layer)\n","\n","model = keras.Model(inputs = in_text, outputs = {'price':p_price, 'type':p_type}, name = 'bi-lstm_model') # Define new model for predicting both price and type\n","\n","# Compile same as previous\n","model.compile(\n","\n","    optimizer=Adam(),                                   # Using Adam as optimizer\n","    loss={                                              # Settings loss computation metrics for 'price' and 'text' objectives\n","        'price': 'sparse_categorical_crossentropy',\n","        'type': 'sparse_categorical_crossentropy',\n","    },\n","    loss_weights={                                      # Addditional weight coeefecients for computing weighted sum\n","        'price': 0.5,\n","        'type': 0.5,\n","    },\n","    metrics={                                           # Metrics to use for evaluation during training\n","        'price': ['SparseCategoricalAccuracy'],\n","        'type': ['SparseCategoricalAccuracy'],\n","    },\n",")\n","\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PdZ13XFx-FHK","executionInfo":{"status":"ok","timestamp":1668806351168,"user_tz":300,"elapsed":787,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"fdf0d7d5-2653-4525-8062-b7174aafe5db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"bi-lstm_model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_5 (InputLayer)           [(None, 100)]        0           []                               \n","                                                                                                  \n"," embedding (Embedding)          (None, 100, 100)     4000000     ['input_5[0][0]']                \n","                                                                                                  \n"," bidirectional (Bidirectional)  (None, 128)          84480       ['embedding[0][0]']              \n","                                                                                                  \n"," dense (Dense)                  (None, 32)           4128        ['bidirectional[0][0]']          \n","                                                                                                  \n"," price (Dense)                  (None, 3)            99          ['dense[0][0]']                  \n","                                                                                                  \n"," type (Dense)                   (None, 24)           792         ['dense[0][0]']                  \n","                                                                                                  \n","==================================================================================================\n","Total params: 4,089,499\n","Trainable params: 4,089,499\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Fit the model to begin training -- Same as before, no Comments\n","history = model.fit(\n","    x=x_tr_text_id,\n","    y={'price': y_tr_price,'type': y_tr_type,},\n","    epochs=10,\n","    batch_size=128,\n","    validation_data=(x_vl_text_id,{'price': y_vl_price,'type': y_vl_type,}),\n","    validation_split=0.2,\n","    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=5)],\n","    verbose=1\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WENyZ1qcAaAG","executionInfo":{"status":"ok","timestamp":1668746663321,"user_tz":300,"elapsed":285657,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"4af61b4a-216b-40db-81d7-7c8b2fc655db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","48/48 [==============================] - 32s 671ms/step - loss: 0.5886 - price_loss: 0.5056 - type_loss: 0.6716 - price_sparse_categorical_accuracy: 0.7976 - type_sparse_categorical_accuracy: 0.8040 - val_loss: 0.8579 - val_price_loss: 0.8111 - val_type_loss: 0.9046 - val_price_sparse_categorical_accuracy: 0.6619 - val_type_sparse_categorical_accuracy: 0.7588\n","Epoch 2/10\n","48/48 [==============================] - 23s 487ms/step - loss: 0.5425 - price_loss: 0.4656 - type_loss: 0.6194 - price_sparse_categorical_accuracy: 0.8156 - type_sparse_categorical_accuracy: 0.8169 - val_loss: 0.8887 - val_price_loss: 0.8483 - val_type_loss: 0.9292 - val_price_sparse_categorical_accuracy: 0.6638 - val_type_sparse_categorical_accuracy: 0.7438\n","Epoch 3/10\n","48/48 [==============================] - 29s 596ms/step - loss: 0.4888 - price_loss: 0.4046 - type_loss: 0.5730 - price_sparse_categorical_accuracy: 0.8410 - type_sparse_categorical_accuracy: 0.8343 - val_loss: 0.9535 - val_price_loss: 0.9230 - val_type_loss: 0.9841 - val_price_sparse_categorical_accuracy: 0.6429 - val_type_sparse_categorical_accuracy: 0.7313\n","Epoch 4/10\n","48/48 [==============================] - 28s 594ms/step - loss: 0.4380 - price_loss: 0.3570 - type_loss: 0.5190 - price_sparse_categorical_accuracy: 0.8651 - type_sparse_categorical_accuracy: 0.8479 - val_loss: 1.0219 - val_price_loss: 1.0364 - val_type_loss: 1.0074 - val_price_sparse_categorical_accuracy: 0.6219 - val_type_sparse_categorical_accuracy: 0.7477\n","Epoch 5/10\n","48/48 [==============================] - 31s 648ms/step - loss: 0.3875 - price_loss: 0.3097 - type_loss: 0.4654 - price_sparse_categorical_accuracy: 0.8856 - type_sparse_categorical_accuracy: 0.8667 - val_loss: 1.0786 - val_price_loss: 1.1252 - val_type_loss: 1.0319 - val_price_sparse_categorical_accuracy: 0.6258 - val_type_sparse_categorical_accuracy: 0.7392\n","Epoch 6/10\n","48/48 [==============================] - 35s 731ms/step - loss: 0.3506 - price_loss: 0.2788 - type_loss: 0.4223 - price_sparse_categorical_accuracy: 0.8989 - type_sparse_categorical_accuracy: 0.8825 - val_loss: 1.1240 - val_price_loss: 1.1715 - val_type_loss: 1.0766 - val_price_sparse_categorical_accuracy: 0.6304 - val_type_sparse_categorical_accuracy: 0.7431\n","Epoch 7/10\n","48/48 [==============================] - 27s 574ms/step - loss: 0.3204 - price_loss: 0.2550 - type_loss: 0.3859 - price_sparse_categorical_accuracy: 0.9094 - type_sparse_categorical_accuracy: 0.8905 - val_loss: 1.1649 - val_price_loss: 1.2107 - val_type_loss: 1.1190 - val_price_sparse_categorical_accuracy: 0.6560 - val_type_sparse_categorical_accuracy: 0.7438\n","Epoch 8/10\n","48/48 [==============================] - 28s 586ms/step - loss: 0.2843 - price_loss: 0.2289 - type_loss: 0.3397 - price_sparse_categorical_accuracy: 0.9192 - type_sparse_categorical_accuracy: 0.9046 - val_loss: 1.2183 - val_price_loss: 1.2999 - val_type_loss: 1.1368 - val_price_sparse_categorical_accuracy: 0.6337 - val_type_sparse_categorical_accuracy: 0.7484\n","Epoch 9/10\n","48/48 [==============================] - 24s 498ms/step - loss: 0.2471 - price_loss: 0.1954 - type_loss: 0.2989 - price_sparse_categorical_accuracy: 0.9323 - type_sparse_categorical_accuracy: 0.9182 - val_loss: 1.3586 - val_price_loss: 1.4476 - val_type_loss: 1.2696 - val_price_sparse_categorical_accuracy: 0.6245 - val_type_sparse_categorical_accuracy: 0.7339\n","Epoch 10/10\n","48/48 [==============================] - 28s 576ms/step - loss: 0.2276 - price_loss: 0.1822 - type_loss: 0.2731 - price_sparse_categorical_accuracy: 0.9377 - type_sparse_categorical_accuracy: 0.9262 - val_loss: 1.3689 - val_price_loss: 1.4446 - val_type_loss: 1.2933 - val_price_sparse_categorical_accuracy: 0.6311 - val_type_sparse_categorical_accuracy: 0.7254\n"]}]},{"cell_type":"markdown","source":["**Trying same Model But With Bi-GRUs**\n","\n","This trial compares performance of Bi-GRU with previous run of Bi-LSTM.\n","\n","* Same layer size to keep it consistent.\n","\n","\n","\n","*Code same as before, no comments.*"],"metadata":{"id":"BMqmCPtlCeFI"}},{"cell_type":"code","source":["# Adding BI-GRU.\n","in_text = Input(batch_shape=(None, max_len))                # Creating input layer\n","e_layer = Embedding(tokenizer.num_words, 100)(in_text)      # Creating Embeddings layer\n","bi_gru = Bidirectional(GRU(64, activation = 'relu'))(e_layer)                  # Creating Bidirectional LSTM Layer\n","d_layer = Dense(32)(bi_gru)\n","\n","# Same as before\n","p_price = Dense(len_price, activation='softmax', name='price')(d_layer)\n","p_type = Dense(len_type, activation='softmax', name='type')(d_layer)\n","\n","model = keras.Model(inputs = in_text, outputs = {'price':p_price, 'type':p_type}, name = 'bi-GRU_model') # Define new model for predicting both price and type\n","\n","model.compile(\n","\n","    optimizer=Adam(),                                   # Using Adam as optimizer\n","    loss={                                              # Settings loss computation metrics for 'price' and 'text' objectives\n","        'price': 'sparse_categorical_crossentropy',\n","        'type': 'sparse_categorical_crossentropy',\n","    },\n","    loss_weights={                                      # Addditional weight coeefecients for computing weighted sum\n","        'price': 0.5,\n","        'type': 0.5,\n","    },\n","    metrics={                                           # Metrics to use for evaluation during training\n","        'price': ['SparseCategoricalAccuracy'],\n","        'type': ['SparseCategoricalAccuracy'],\n","    },\n",")\n","\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cD5wdJjICoUP","executionInfo":{"status":"ok","timestamp":1668826722435,"user_tz":300,"elapsed":1050,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"c1155b69-0f01-4eac-c240-cf228a4f84c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"bi-GRU_model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 100)]        0           []                               \n","                                                                                                  \n"," embedding (Embedding)          (None, 100, 100)     4000000     ['input_1[0][0]']                \n","                                                                                                  \n"," bidirectional (Bidirectional)  (None, 128)          63744       ['embedding[0][0]']              \n","                                                                                                  \n"," dense (Dense)                  (None, 32)           4128        ['bidirectional[0][0]']          \n","                                                                                                  \n"," price (Dense)                  (None, 3)            99          ['dense[0][0]']                  \n","                                                                                                  \n"," type (Dense)                   (None, 24)           792         ['dense[0][0]']                  \n","                                                                                                  \n","==================================================================================================\n","Total params: 4,068,763\n","Trainable params: 4,068,763\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Fit the model to begin training -- Same as before, no Comments\n","history = model.fit(\n","    x=x_tr_text_id,\n","    y={'price': y_tr_price,'type': y_tr_type,},\n","    epochs=10,\n","    batch_size=128,\n","    validation_data=(x_vl_text_id,{'price': y_vl_price,'type': y_vl_type,}),\n","    validation_split=0.2,\n","    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=5, restore_best_weights = 'True')],\n","    verbose=1\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j-QfjRgSDJBV","executionInfo":{"status":"ok","timestamp":1668826994162,"user_tz":300,"elapsed":268594,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"b8d37141-373f-4663-f7b2-83f3e4003a31"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","48/48 [==============================] - 45s 802ms/step - loss: 1.4926 - price_loss: 0.9607 - type_loss: 2.0245 - price_sparse_categorical_accuracy: 0.5896 - type_sparse_categorical_accuracy: 0.7137 - val_loss: 0.9581 - val_price_loss: 0.8342 - val_type_loss: 1.0821 - val_price_sparse_categorical_accuracy: 0.6173 - val_type_sparse_categorical_accuracy: 0.7529\n","Epoch 2/10\n","48/48 [==============================] - 27s 564ms/step - loss: 0.8848 - price_loss: 0.7965 - type_loss: 0.9732 - price_sparse_categorical_accuracy: 0.6269 - type_sparse_categorical_accuracy: 0.7566 - val_loss: 0.9005 - val_price_loss: 0.7999 - val_type_loss: 1.0012 - val_price_sparse_categorical_accuracy: 0.6311 - val_type_sparse_categorical_accuracy: 0.7529\n","Epoch 3/10\n","48/48 [==============================] - 18s 378ms/step - loss: 0.8188 - price_loss: 0.7429 - type_loss: 0.8948 - price_sparse_categorical_accuracy: 0.6627 - type_sparse_categorical_accuracy: 0.7566 - val_loss: 0.8851 - val_price_loss: 0.7886 - val_type_loss: 0.9816 - val_price_sparse_categorical_accuracy: 0.6448 - val_type_sparse_categorical_accuracy: 0.7529\n","Epoch 4/10\n","48/48 [==============================] - 21s 437ms/step - loss: 0.8284 - price_loss: 0.7742 - type_loss: 0.8825 - price_sparse_categorical_accuracy: 0.6681 - type_sparse_categorical_accuracy: 0.7573 - val_loss: 0.9008 - val_price_loss: 0.8006 - val_type_loss: 1.0011 - val_price_sparse_categorical_accuracy: 0.6317 - val_type_sparse_categorical_accuracy: 0.7529\n","Epoch 5/10\n","48/48 [==============================] - 20s 426ms/step - loss: 0.7734 - price_loss: 0.6935 - type_loss: 0.8534 - price_sparse_categorical_accuracy: 0.6891 - type_sparse_categorical_accuracy: 0.7605 - val_loss: 0.8757 - val_price_loss: 0.7950 - val_type_loss: 0.9564 - val_price_sparse_categorical_accuracy: 0.6461 - val_type_sparse_categorical_accuracy: 0.7588\n","Epoch 6/10\n","48/48 [==============================] - 21s 444ms/step - loss: 0.7065 - price_loss: 0.6382 - type_loss: 0.7747 - price_sparse_categorical_accuracy: 0.7168 - type_sparse_categorical_accuracy: 0.7725 - val_loss: 0.8653 - val_price_loss: 0.7860 - val_type_loss: 0.9446 - val_price_sparse_categorical_accuracy: 0.6678 - val_type_sparse_categorical_accuracy: 0.7602\n","Epoch 7/10\n","48/48 [==============================] - 18s 375ms/step - loss: 0.6727 - price_loss: 0.6204 - type_loss: 0.7251 - price_sparse_categorical_accuracy: 0.7563 - type_sparse_categorical_accuracy: 0.7886 - val_loss: 0.8917 - val_price_loss: 0.8208 - val_type_loss: 0.9627 - val_price_sparse_categorical_accuracy: 0.6651 - val_type_sparse_categorical_accuracy: 0.7503\n","Epoch 8/10\n","48/48 [==============================] - 20s 429ms/step - loss: 0.5770 - price_loss: 0.5009 - type_loss: 0.6530 - price_sparse_categorical_accuracy: 0.7894 - type_sparse_categorical_accuracy: 0.8069 - val_loss: 0.9359 - val_price_loss: 0.8701 - val_type_loss: 1.0016 - val_price_sparse_categorical_accuracy: 0.6573 - val_type_sparse_categorical_accuracy: 0.7497\n","Epoch 9/10\n","48/48 [==============================] - 18s 381ms/step - loss: 0.5245 - price_loss: 0.4465 - type_loss: 0.6025 - price_sparse_categorical_accuracy: 0.8145 - type_sparse_categorical_accuracy: 0.8182 - val_loss: 0.9912 - val_price_loss: 0.9350 - val_type_loss: 1.0474 - val_price_sparse_categorical_accuracy: 0.6396 - val_type_sparse_categorical_accuracy: 0.7497\n","Epoch 10/10\n","48/48 [==============================] - 21s 444ms/step - loss: 0.4816 - price_loss: 0.4001 - type_loss: 0.5631 - price_sparse_categorical_accuracy: 0.8376 - type_sparse_categorical_accuracy: 0.8335 - val_loss: 1.0637 - val_price_loss: 1.0352 - val_type_loss: 1.0922 - val_price_sparse_categorical_accuracy: 0.6507 - val_type_sparse_categorical_accuracy: 0.7556\n"]}]},{"cell_type":"code","source":["# Predict model and generate files for submission (Disabled to prevent unnecessary submissions.)\n","# y_predict = model.predict(\n","# x_test_summary,\n","# )\n","\n","# price_predicted = y_predict['price']\n","# print(price_predicted)\n","# price_category_predicted = np.argmax(price_predicted, axis=1)\n","# print(price_category_predicted)\n","\n","# pd.DataFrame({'id': x_test_df.id,'price': price_category_predicted}).to_csv('/content/drive/MyDrive/cisc/A4_5/submGRU.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q4Lbc_V00xC8","executionInfo":{"status":"ok","timestamp":1668827169404,"user_tz":300,"elapsed":11276,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"d78228a1-bee2-4b87-9f6b-7d629313527e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["230/230 [==============================] - 6s 25ms/step\n","[[2.6408705e-01 6.3715941e-01 9.8753586e-02]\n"," [9.9881595e-01 1.1365864e-03 4.7415771e-05]\n"," [9.7829759e-01 1.8725380e-02 2.9770448e-03]\n"," ...\n"," [4.4506723e-01 4.8081037e-01 7.4122407e-02]\n"," [9.9997443e-01 2.4455394e-05 1.0252315e-06]\n"," [6.6637494e-02 8.2239866e-01 1.1096380e-01]]\n","[1 0 0 ... 1 0 1]\n"]}]},{"cell_type":"markdown","source":["## Observation\n","\n","The Bi-GRU Based model features far lesser trainable params, took roughly the same time to execute (around 20-25s at an average).\n","\n","However, the Bi_GRU model performs slightly better with\n","\n","**val_price_sparse_categorical_accuracy** = 63% vs 65.3%\n","\n","and\n","\n","**val_type_sparse_categorical_accuracy** = 72% vs 75.3%\n","\n"],"metadata":{"id":"JcZpSwPFEjBy"}},{"cell_type":"markdown","source":["# Text Inputs: Attention layer"],"metadata":{"id":"EifsEGsj_xPP"}},{"cell_type":"markdown","source":["This block builds on top of previous execution of Bidirectional GRU to add attention mechanism for text inputs.\n","\n","Focus of prediction is limited to Price only to save time and test the performance quickly.\n","\n","Disclosure: Implementation of Attention class taken from other sources. All credits to original author. I am not experienced enough to implement attention class myself :(\n","\n","But the remaining implemntation is inline to other code in this assignemnt."],"metadata":{"id":"7WLeA4xyUIZz"}},{"cell_type":"code","metadata":{"id":"t-FyE587xReE"},"source":["# Implementation of Attention Class Adapted from discussion on: https://analyticsindiamag.com/a-beginners-guide-to-using-attention-layer-in-neural-networks/\n","# All credits to original Author for implementation\n","# Only used here to facilitate attention based mechanism.\n","\n","from tensorflow.keras.layers import Layer\n","from tensorflow.keras import backend as B\n","class att(Layer):\n","\n","    def __init__(self, return_sequences=True):\n","        self.return_sequences = return_sequences\n","        super(att,self).__init__()\n","\n","    def build(self, input_shape):\n","\n","        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1],1),\n","                               initializer=\"normal\")\n","        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1),\n","                               initializer=\"zeros\")\n","\n","        super(att,self).build(input_shape)\n","\n","    def call(self, x):\n","\n","        e = B.tanh(K.dot(x,self.W)+self.b)\n","        a = B.softmax(e, axis=1)\n","        output = x*a\n","\n","        if self.return_sequences:\n","            return output\n","\n","        return B.sum(output, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Creating a sequential model to implement attention layer\n","\n","m_att = Sequential([                                                 # Begin Sequential model.\n","Input(batch_shape=(None, max_len)),                                  # Input layer to add inputs\n","Embedding(tokenizer.num_words, 100),                                 # Create embeddings\n","Bidirectional(GRU(64, return_sequences=True)),                       # Bi-GRU Layer, similar to previous result\n","att(return_sequences=False),                                         # Using the Attention layer from the class\n","Dense(len_price, activation='softmax', name='price'),                # Final dense layer\n","])\n","\n","m_att.summary()\n","\n","m_att.compile(\n","    optimizer=Adam(),                         # Tried different optimmizers but Adam provided more reproduceable outputs\n","    loss='sparse_categorical_crossentropy',                    # Settings loss computation metrics for 'price'\n","    metrics=['SparseCategoricalAccuracy']                     # Metrics to use for evaluation during training\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M1vZp0aPR4t7","executionInfo":{"status":"ok","timestamp":1668834865531,"user_tz":300,"elapsed":1133,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"ebaf960b-434c-40f3-fcac-f01da2215361"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_20 (Embedding)    (None, 100, 100)          4000000   \n","                                                                 \n"," bidirectional_17 (Bidirecti  (None, 100, 128)         63744     \n"," onal)                                                           \n","                                                                 \n"," attention_11 (attention)    (None, 128)               228       \n","                                                                 \n"," price (Dense)               (None, 3)                 387       \n","                                                                 \n","=================================================================\n","Total params: 4,064,359\n","Trainable params: 4,064,359\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Fit the model to begin training\n","history = m_att.fit(\n","    x = x_tr_text_id,\n","    y = y_tr_price,\n","    epochs = 10,\n","    batch_size = 32,\n","    validation_data = (x_vl_text_id, y_vl_price),\n","    validation_split = 0.2,\n","    verbose = 1\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mtg6iDaqWtw-","executionInfo":{"status":"ok","timestamp":1668835315337,"user_tz":300,"elapsed":445921,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"eddf15d7-4d9e-4d63-8ff4-51ac2886d766"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","191/191 [==============================] - 45s 215ms/step - loss: 0.8053 - sparse_categorical_accuracy: 0.6379 - val_loss: 0.7443 - val_sparse_categorical_accuracy: 0.6769\n","Epoch 2/10\n","191/191 [==============================] - 47s 244ms/step - loss: 0.6446 - sparse_categorical_accuracy: 0.7171 - val_loss: 0.7208 - val_sparse_categorical_accuracy: 0.6887\n","Epoch 3/10\n","191/191 [==============================] - 42s 219ms/step - loss: 0.5206 - sparse_categorical_accuracy: 0.7800 - val_loss: 0.7736 - val_sparse_categorical_accuracy: 0.6474\n","Epoch 4/10\n","191/191 [==============================] - 40s 212ms/step - loss: 0.4028 - sparse_categorical_accuracy: 0.8376 - val_loss: 0.8763 - val_sparse_categorical_accuracy: 0.6494\n","Epoch 5/10\n","191/191 [==============================] - 37s 193ms/step - loss: 0.3072 - sparse_categorical_accuracy: 0.8830 - val_loss: 1.1324 - val_sparse_categorical_accuracy: 0.6442\n","Epoch 6/10\n","191/191 [==============================] - 46s 242ms/step - loss: 0.2387 - sparse_categorical_accuracy: 0.9118 - val_loss: 1.1783 - val_sparse_categorical_accuracy: 0.6527\n","Epoch 7/10\n","191/191 [==============================] - 37s 192ms/step - loss: 0.1938 - sparse_categorical_accuracy: 0.9282 - val_loss: 1.3463 - val_sparse_categorical_accuracy: 0.6370\n","Epoch 8/10\n","191/191 [==============================] - 43s 224ms/step - loss: 0.1659 - sparse_categorical_accuracy: 0.9385 - val_loss: 1.4404 - val_sparse_categorical_accuracy: 0.6330\n","Epoch 9/10\n","191/191 [==============================] - 42s 220ms/step - loss: 0.1407 - sparse_categorical_accuracy: 0.9482 - val_loss: 1.4717 - val_sparse_categorical_accuracy: 0.6350\n","Epoch 10/10\n","191/191 [==============================] - 34s 175ms/step - loss: 0.1338 - sparse_categorical_accuracy: 0.9510 - val_loss: 1.5436 - val_sparse_categorical_accuracy: 0.6035\n"]}]},{"cell_type":"markdown","source":["# Image Inputs: CNNs with Dropout"],"metadata":{"id":"JXX8oog-6dAy"}},{"cell_type":"markdown","source":["This block explores predicting prices / type based on image inputs only using CNNs with Dropout."],"metadata":{"id":"F2ibDZw76mt0"}},{"cell_type":"code","source":["# Adding Conculutional Architecture for Image based prediction (Derived from Template)\n","in_layer = keras.Input(batch_shape=(None, 64, 64, 2))         # Input layer to take images and resize them for the batch\n","conv = Conv2D(32, 5, padding = 'same')(in_layer)              # Conv Layer with 32 filters and Kernel_size = (5x5)\n","mxpool = MaxPool2D(2)(conv)                                   # Applying MaxPooling for dimensionality reduction\n","dr = Dropout(0.25)(mxpool)                                            # Applying a small Dropout\n","flat = Flatten()(dr)                                      # Flattening the output of Conv + Dropout\n","\n","# Same as before\n","p_price = Dense(len_price, activation='softmax', name='price')(flat)\n","p_type = Dense(len_type, activation='softmax', name='type')(flat)\n","\n","m_cnn = keras.Model(inputs = in_layer, outputs = {'price':p_price, 'type':p_type}, name = 'CNN_Dr_Model') # Define new model for predicting both price and type\n","\n","m_cnn.compile(\n","\n","    optimizer=Adam(),                                   # Using Adam as optimizer\n","    loss={                                              # Settings loss computation metrics for 'price' and 'text' objectives\n","        'price': 'sparse_categorical_crossentropy',\n","        'type': 'sparse_categorical_crossentropy',\n","    },\n","    loss_weights={                                      # Addditional weight coeefecients for computing weighted sum\n","        'price': 0.5,\n","        'type': 0.5,\n","    },\n","    metrics={                                           # Metrics to use for evaluation during training\n","        'price': ['SparseCategoricalAccuracy'],\n","        'type': ['SparseCategoricalAccuracy'],\n","    },\n",")\n","\n","m_cnn.summary()                                         # Displaying the summary of the compiled architecture"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZSNxRV9BGK6A","executionInfo":{"status":"ok","timestamp":1668806478860,"user_tz":300,"elapsed":466,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"201e2ea1-f858-4c62-c006-111889945344"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"CNN_Dr_Model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_6 (InputLayer)           [(None, 64, 64, 2)]  0           []                               \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 64, 64, 32)   608         ['input_6[0][0]']                \n","                                                                                                  \n"," max_pooling2d_4 (MaxPooling2D)  (None, 32, 32, 32)  0           ['conv2d_4[0][0]']               \n","                                                                                                  \n"," dropout_3 (Dropout)            (None, 32, 32, 32)   0           ['max_pooling2d_4[0][0]']        \n","                                                                                                  \n"," flatten_4 (Flatten)            (None, 32768)        0           ['dropout_3[0][0]']              \n","                                                                                                  \n"," price (Dense)                  (None, 3)            98307       ['flatten_4[0][0]']              \n","                                                                                                  \n"," type (Dense)                   (None, 24)           786456      ['flatten_4[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 885,371\n","Trainable params: 885,371\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Fit the model to begin training -- Same as before, no Comments\n","history = m_cnn.fit(\n","    x=x_tr_image,\n","    y={'price': y_tr_price,'type': y_tr_type,},\n","    epochs=10,\n","    batch_size=128,\n","    validation_data=(x_vl_image,{'price': y_vl_price,'type': y_vl_type,}),\n","    validation_split=0.15,\n","    # callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=5)],  # Call back disabled to see how it performs initially for all the epochs\n","    verbose=1\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cq1wQi45KMqF","executionInfo":{"status":"ok","timestamp":1668806688617,"user_tz":300,"elapsed":203364,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"3ba0c00a-542e-47de-c82e-458674094e03"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","48/48 [==============================] - 21s 408ms/step - loss: 263.4845 - price_loss: 206.8071 - type_loss: 320.1617 - price_sparse_categorical_accuracy: 0.5061 - type_sparse_categorical_accuracy: 0.5661 - val_loss: 51.2093 - val_price_loss: 17.6254 - val_type_loss: 84.7932 - val_price_sparse_categorical_accuracy: 0.5609 - val_type_sparse_categorical_accuracy: 0.7084\n","Epoch 2/10\n","48/48 [==============================] - 24s 497ms/step - loss: 32.8818 - price_loss: 15.7611 - type_loss: 50.0026 - price_sparse_categorical_accuracy: 0.5366 - type_sparse_categorical_accuracy: 0.6001 - val_loss: 24.8601 - val_price_loss: 8.7166 - val_type_loss: 41.0035 - val_price_sparse_categorical_accuracy: 0.4528 - val_type_sparse_categorical_accuracy: 0.5668\n","Epoch 3/10\n","48/48 [==============================] - 21s 429ms/step - loss: 23.1391 - price_loss: 12.6633 - type_loss: 33.6149 - price_sparse_categorical_accuracy: 0.5366 - type_sparse_categorical_accuracy: 0.6207 - val_loss: 18.6762 - val_price_loss: 12.1224 - val_type_loss: 25.2299 - val_price_sparse_categorical_accuracy: 0.6114 - val_type_sparse_categorical_accuracy: 0.5596\n","Epoch 4/10\n","48/48 [==============================] - 20s 426ms/step - loss: 21.0194 - price_loss: 13.2499 - type_loss: 28.7889 - price_sparse_categorical_accuracy: 0.5563 - type_sparse_categorical_accuracy: 0.6155 - val_loss: 18.9599 - val_price_loss: 12.0082 - val_type_loss: 25.9116 - val_price_sparse_categorical_accuracy: 0.5858 - val_type_sparse_categorical_accuracy: 0.5505\n","Epoch 5/10\n","48/48 [==============================] - 18s 382ms/step - loss: 13.8408 - price_loss: 10.8422 - type_loss: 16.8394 - price_sparse_categorical_accuracy: 0.5563 - type_sparse_categorical_accuracy: 0.6505 - val_loss: 26.8767 - val_price_loss: 11.3762 - val_type_loss: 42.3772 - val_price_sparse_categorical_accuracy: 0.4522 - val_type_sparse_categorical_accuracy: 0.5983\n","Epoch 6/10\n","48/48 [==============================] - 18s 381ms/step - loss: 11.8040 - price_loss: 8.1099 - type_loss: 15.4981 - price_sparse_categorical_accuracy: 0.5812 - type_sparse_categorical_accuracy: 0.6592 - val_loss: 15.4335 - val_price_loss: 8.7636 - val_type_loss: 22.1035 - val_price_sparse_categorical_accuracy: 0.5950 - val_type_sparse_categorical_accuracy: 0.7136\n","Epoch 7/10\n","48/48 [==============================] - 18s 383ms/step - loss: 9.4839 - price_loss: 8.6079 - type_loss: 10.3598 - price_sparse_categorical_accuracy: 0.5825 - type_sparse_categorical_accuracy: 0.6689 - val_loss: 15.6488 - val_price_loss: 10.1535 - val_type_loss: 21.1440 - val_price_sparse_categorical_accuracy: 0.6009 - val_type_sparse_categorical_accuracy: 0.7064\n","Epoch 8/10\n","48/48 [==============================] - 18s 383ms/step - loss: 7.7634 - price_loss: 7.1014 - type_loss: 8.4253 - price_sparse_categorical_accuracy: 0.5994 - type_sparse_categorical_accuracy: 0.6773 - val_loss: 15.2772 - val_price_loss: 9.8952 - val_type_loss: 20.6593 - val_price_sparse_categorical_accuracy: 0.6009 - val_type_sparse_categorical_accuracy: 0.7267\n","Epoch 9/10\n","48/48 [==============================] - 18s 383ms/step - loss: 7.2399 - price_loss: 6.8133 - type_loss: 7.6664 - price_sparse_categorical_accuracy: 0.6073 - type_sparse_categorical_accuracy: 0.7064 - val_loss: 12.8584 - val_price_loss: 7.9773 - val_type_loss: 17.7394 - val_price_sparse_categorical_accuracy: 0.5138 - val_type_sparse_categorical_accuracy: 0.6606\n","Epoch 10/10\n","48/48 [==============================] - 18s 383ms/step - loss: 6.5212 - price_loss: 5.8890 - type_loss: 7.1533 - price_sparse_categorical_accuracy: 0.6245 - type_sparse_categorical_accuracy: 0.7087 - val_loss: 12.2336 - val_price_loss: 7.5521 - val_type_loss: 16.9151 - val_price_sparse_categorical_accuracy: 0.4751 - val_type_sparse_categorical_accuracy: 0.6343\n"]}]},{"cell_type":"markdown","source":["**Observation:**\n","\n","The performance of the model is terrible. It starts off good, and while the loss si reducing, there is no conclusible result based on val_loss. Requires further tuning and modified architecture.\n"],"metadata":{"id":"jPu748mMpBFY"}},{"cell_type":"markdown","source":["The next Trial makes modifications to the CNN architecture and changes following parameters:\n","\n","* Changed Activation\n","\n","* Increased Dropout rate\n","\n","* Added more layers\n","\n","\n"],"metadata":{"id":"D6GYxttgpexB"}},{"cell_type":"code","source":["# Adding Deeper Conculutional Architecture for Image based prediction\n","\n","in_layer = keras.Input(batch_shape=(None, 64, 64, 2))\n","conv1 = Conv2D(16, 3, padding = 'same', activation = 'relu')(in_layer)      # Conv1 Layer\n","mxpool1 = MaxPool2D(2)(conv1)\n","dr1 = Dropout(0.5)(mxpool1)\n","conv2 = Conv2D(32, 3, padding = 'same', activation = 'relu')(dr1)           # Conv 2 Layer for deeper feature learning\n","mxpool2 = MaxPool2D(2)(conv2)\n","dr2 = Dropout(0.5)(mxpool2)\n","conv3 = Conv2D(64, 3, padding = 'same', activation = 'relu')(dr2)           # Conv3 Layer for even more\n","dr3 = Dropout(0.5)(conv3)                                                   # No maxpooling for last layer\n","d_layer = Dense(128, activation = 'relu')(dr3)\n","flat = Flatten()(d_layer)\n","\n","# Same as before\n","p_price = Dense(len_price, activation='softmax', name='price')(flat)\n","p_type = Dense(len_type, activation='softmax', name='type')(flat)\n","\n","m_cnn2 = keras.Model(inputs = in_layer, outputs = {'price':p_price, 'type':p_type}, name = 'CNN_Model2')\n","m_cnn2.compile(\n","\n","    optimizer=Adam(),                                   # Using Adam as optimizer\n","    loss={                                              # Settings loss computation metrics for 'price' and 'text' objectives\n","        'price': 'sparse_categorical_crossentropy',\n","        'type': 'sparse_categorical_crossentropy',\n","    },\n","\n","    metrics={                                           # Metrics to use for evaluation during training\n","        'price': ['SparseCategoricalAccuracy'],\n","        'type': ['SparseCategoricalAccuracy'],\n","    },\n",")\n","\n","m_cnn2.summary()                                         # Displaying the summary of the compiled architecture"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EvixCz_rpWic","executionInfo":{"status":"ok","timestamp":1668817017448,"user_tz":300,"elapsed":508,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"aa1e7b6a-11c5-4b27-fde9-ed2fe274df0b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"CNN_Model2\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_17 (InputLayer)          [(None, 64, 64, 2)]  0           []                               \n","                                                                                                  \n"," conv2d_35 (Conv2D)             (None, 64, 64, 16)   304         ['input_17[0][0]']               \n","                                                                                                  \n"," max_pooling2d_25 (MaxPooling2D  (None, 32, 32, 16)  0           ['conv2d_35[0][0]']              \n"," )                                                                                                \n","                                                                                                  \n"," dropout_34 (Dropout)           (None, 32, 32, 16)   0           ['max_pooling2d_25[0][0]']       \n","                                                                                                  \n"," conv2d_36 (Conv2D)             (None, 32, 32, 32)   4640        ['dropout_34[0][0]']             \n","                                                                                                  \n"," max_pooling2d_26 (MaxPooling2D  (None, 16, 16, 32)  0           ['conv2d_36[0][0]']              \n"," )                                                                                                \n","                                                                                                  \n"," dropout_35 (Dropout)           (None, 16, 16, 32)   0           ['max_pooling2d_26[0][0]']       \n","                                                                                                  \n"," conv2d_37 (Conv2D)             (None, 16, 16, 64)   18496       ['dropout_35[0][0]']             \n","                                                                                                  \n"," dropout_36 (Dropout)           (None, 16, 16, 64)   0           ['conv2d_37[0][0]']              \n","                                                                                                  \n"," dense_4 (Dense)                (None, 16, 16, 128)  8320        ['dropout_36[0][0]']             \n","                                                                                                  \n"," flatten_15 (Flatten)           (None, 32768)        0           ['dense_4[0][0]']                \n","                                                                                                  \n"," price (Dense)                  (None, 3)            98307       ['flatten_15[0][0]']             \n","                                                                                                  \n"," type (Dense)                   (None, 24)           786456      ['flatten_15[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 916,523\n","Trainable params: 916,523\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Fit the model to begin training -- Same as before, no Comments\n","history = m_cnn2.fit(\n","    x=x_tr_image,\n","    y={'price': y_tr_price,'type': y_tr_type,},\n","    epochs=20,\n","    batch_size=128,\n","    validation_data=(x_vl_image,{'price': y_vl_price,'type': y_vl_type,}),\n","    validation_split=0.2,\n","    verbose=1\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8pGoCB-tsPBH","executionInfo":{"status":"ok","timestamp":1668817718534,"user_tz":300,"elapsed":695886,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"3763fc2e-a062-49db-9918-b34ed28d2e9b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","48/48 [==============================] - 36s 717ms/step - loss: 44.4613 - price_loss: 27.1838 - type_loss: 17.2774 - price_sparse_categorical_accuracy: 0.5132 - type_sparse_categorical_accuracy: 0.6660 - val_loss: 4.2114 - val_price_loss: 1.0897 - val_type_loss: 3.1218 - val_price_sparse_categorical_accuracy: 0.3283 - val_type_sparse_categorical_accuracy: 0.4600\n","Epoch 2/20\n","48/48 [==============================] - 35s 730ms/step - loss: 2.0753 - price_loss: 0.8981 - type_loss: 1.1772 - price_sparse_categorical_accuracy: 0.5645 - type_sparse_categorical_accuracy: 0.7579 - val_loss: 4.1381 - val_price_loss: 1.0711 - val_type_loss: 3.0669 - val_price_sparse_categorical_accuracy: 0.6193 - val_type_sparse_categorical_accuracy: 0.1540\n","Epoch 3/20\n","48/48 [==============================] - 35s 727ms/step - loss: 2.0089 - price_loss: 0.8773 - type_loss: 1.1315 - price_sparse_categorical_accuracy: 0.5983 - type_sparse_categorical_accuracy: 0.7582 - val_loss: 4.0701 - val_price_loss: 1.0613 - val_type_loss: 3.0089 - val_price_sparse_categorical_accuracy: 0.6193 - val_type_sparse_categorical_accuracy: 0.0937\n","Epoch 4/20\n","48/48 [==============================] - 36s 746ms/step - loss: 2.0086 - price_loss: 0.8737 - type_loss: 1.1349 - price_sparse_categorical_accuracy: 0.6061 - type_sparse_categorical_accuracy: 0.7577 - val_loss: 4.0553 - val_price_loss: 1.0610 - val_type_loss: 2.9943 - val_price_sparse_categorical_accuracy: 0.6193 - val_type_sparse_categorical_accuracy: 0.1245\n","Epoch 5/20\n","48/48 [==============================] - 34s 702ms/step - loss: 1.9930 - price_loss: 0.8650 - type_loss: 1.1280 - price_sparse_categorical_accuracy: 0.6048 - type_sparse_categorical_accuracy: 0.7581 - val_loss: 4.0180 - val_price_loss: 1.0575 - val_type_loss: 2.9604 - val_price_sparse_categorical_accuracy: 0.6193 - val_type_sparse_categorical_accuracy: 0.6828\n","Epoch 6/20\n","48/48 [==============================] - 33s 699ms/step - loss: 1.9749 - price_loss: 0.8666 - type_loss: 1.1083 - price_sparse_categorical_accuracy: 0.6097 - type_sparse_categorical_accuracy: 0.7581 - val_loss: 4.0473 - val_price_loss: 1.0578 - val_type_loss: 2.9894 - val_price_sparse_categorical_accuracy: 0.6193 - val_type_sparse_categorical_accuracy: 0.7379\n","Epoch 7/20\n","48/48 [==============================] - 31s 656ms/step - loss: 1.9758 - price_loss: 0.8662 - type_loss: 1.1096 - price_sparse_categorical_accuracy: 0.6102 - type_sparse_categorical_accuracy: 0.7581 - val_loss: 4.0365 - val_price_loss: 1.0533 - val_type_loss: 2.9833 - val_price_sparse_categorical_accuracy: 0.6193 - val_type_sparse_categorical_accuracy: 0.7471\n","Epoch 8/20\n","48/48 [==============================] - 34s 692ms/step - loss: 1.9523 - price_loss: 0.8532 - type_loss: 1.0991 - price_sparse_categorical_accuracy: 0.6148 - type_sparse_categorical_accuracy: 0.7581 - val_loss: 3.8087 - val_price_loss: 1.0412 - val_type_loss: 2.7674 - val_price_sparse_categorical_accuracy: 0.6193 - val_type_sparse_categorical_accuracy: 0.7471\n","Epoch 9/20\n","48/48 [==============================] - 36s 747ms/step - loss: 1.9375 - price_loss: 0.8514 - type_loss: 1.0861 - price_sparse_categorical_accuracy: 0.6135 - type_sparse_categorical_accuracy: 0.7581 - val_loss: 3.6476 - val_price_loss: 1.0235 - val_type_loss: 2.6241 - val_price_sparse_categorical_accuracy: 0.6193 - val_type_sparse_categorical_accuracy: 0.2300\n","Epoch 10/20\n","48/48 [==============================] - 34s 702ms/step - loss: 1.9361 - price_loss: 0.8535 - type_loss: 1.0826 - price_sparse_categorical_accuracy: 0.6181 - type_sparse_categorical_accuracy: 0.7581 - val_loss: 3.5767 - val_price_loss: 1.0045 - val_type_loss: 2.5722 - val_price_sparse_categorical_accuracy: 0.6193 - val_type_sparse_categorical_accuracy: 0.0144\n","Epoch 11/20\n","48/48 [==============================] - 34s 701ms/step - loss: 1.9204 - price_loss: 0.8516 - type_loss: 1.0688 - price_sparse_categorical_accuracy: 0.6173 - type_sparse_categorical_accuracy: 0.7581 - val_loss: 3.5017 - val_price_loss: 0.9727 - val_type_loss: 2.5289 - val_price_sparse_categorical_accuracy: 0.6193 - val_type_sparse_categorical_accuracy: 0.0085\n","Epoch 12/20\n","48/48 [==============================] - 34s 700ms/step - loss: 1.9113 - price_loss: 0.8499 - type_loss: 1.0614 - price_sparse_categorical_accuracy: 0.6196 - type_sparse_categorical_accuracy: 0.7581 - val_loss: 3.2686 - val_price_loss: 0.9204 - val_type_loss: 2.3482 - val_price_sparse_categorical_accuracy: 0.6193 - val_type_sparse_categorical_accuracy: 0.0537\n","Epoch 13/20\n","48/48 [==============================] - 36s 747ms/step - loss: 1.9019 - price_loss: 0.8454 - type_loss: 1.0565 - price_sparse_categorical_accuracy: 0.6184 - type_sparse_categorical_accuracy: 0.7581 - val_loss: 3.0851 - val_price_loss: 0.9020 - val_type_loss: 2.1831 - val_price_sparse_categorical_accuracy: 0.6193 - val_type_sparse_categorical_accuracy: 0.0439\n","Epoch 14/20\n","48/48 [==============================] - 34s 702ms/step - loss: 1.8892 - price_loss: 0.8441 - type_loss: 1.0452 - price_sparse_categorical_accuracy: 0.6219 - type_sparse_categorical_accuracy: 0.7581 - val_loss: 3.0640 - val_price_loss: 0.8827 - val_type_loss: 2.1813 - val_price_sparse_categorical_accuracy: 0.6193 - val_type_sparse_categorical_accuracy: 0.0079\n","Epoch 15/20\n","48/48 [==============================] - 34s 701ms/step - loss: 1.8854 - price_loss: 0.8446 - type_loss: 1.0407 - price_sparse_categorical_accuracy: 0.6204 - type_sparse_categorical_accuracy: 0.7581 - val_loss: 2.6560 - val_price_loss: 0.8585 - val_type_loss: 1.7976 - val_price_sparse_categorical_accuracy: 0.6193 - val_type_sparse_categorical_accuracy: 0.7471\n","Epoch 16/20\n","48/48 [==============================] - 34s 701ms/step - loss: 1.8740 - price_loss: 0.8369 - type_loss: 1.0371 - price_sparse_categorical_accuracy: 0.6224 - type_sparse_categorical_accuracy: 0.7581 - val_loss: 2.4142 - val_price_loss: 0.8601 - val_type_loss: 1.5541 - val_price_sparse_categorical_accuracy: 0.6193 - val_type_sparse_categorical_accuracy: 0.7471\n","Epoch 17/20\n","48/48 [==============================] - 31s 655ms/step - loss: 1.8717 - price_loss: 0.8377 - type_loss: 1.0339 - price_sparse_categorical_accuracy: 0.6207 - type_sparse_categorical_accuracy: 0.7581 - val_loss: 2.3087 - val_price_loss: 0.8509 - val_type_loss: 1.4578 - val_price_sparse_categorical_accuracy: 0.6193 - val_type_sparse_categorical_accuracy: 0.7471\n","Epoch 18/20\n","48/48 [==============================] - 36s 746ms/step - loss: 1.8666 - price_loss: 0.8351 - type_loss: 1.0316 - price_sparse_categorical_accuracy: 0.6209 - type_sparse_categorical_accuracy: 0.7581 - val_loss: 2.1536 - val_price_loss: 0.8511 - val_type_loss: 1.3026 - val_price_sparse_categorical_accuracy: 0.6193 - val_type_sparse_categorical_accuracy: 0.7471\n","Epoch 19/20\n","48/48 [==============================] - 33s 699ms/step - loss: 1.8582 - price_loss: 0.8359 - type_loss: 1.0222 - price_sparse_categorical_accuracy: 0.6214 - type_sparse_categorical_accuracy: 0.7581 - val_loss: 2.0730 - val_price_loss: 0.8472 - val_type_loss: 1.2258 - val_price_sparse_categorical_accuracy: 0.6193 - val_type_sparse_categorical_accuracy: 0.7471\n","Epoch 20/20\n","48/48 [==============================] - 34s 702ms/step - loss: 1.8525 - price_loss: 0.8376 - type_loss: 1.0149 - price_sparse_categorical_accuracy: 0.6207 - type_sparse_categorical_accuracy: 0.7581 - val_loss: 2.0377 - val_price_loss: 0.8407 - val_type_loss: 1.1970 - val_price_sparse_categorical_accuracy: 0.6193 - val_type_sparse_categorical_accuracy: 0.7471\n"]}]},{"cell_type":"code","source":["# # Predict model and generate files for submission (Disabled to prevent unnecessary submissions.)\n","# y_predict = m_cnn2.predict(\n","#      x_test_image\n","# )\n","\n","# price_predicted = y_predict['price']\n","# print(price_predicted)\n","# price_category_predicted = np.argmax(price_predicted, axis=1)\n","# print(price_category_predicted)\n","\n","# pd.DataFrame({'id': x_test_df.id,'price': price_category_predicted}).to_csv('/content/drive/MyDrive/cisc/A4_5/subm3.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XDLBLJvU-w1C","executionInfo":{"status":"ok","timestamp":1668812671232,"user_tz":300,"elapsed":22250,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"4ce7b078-9613-46f2-9030-02744eeb773b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["230/230 [==============================] - 14s 59ms/step\n","[[0.47574157 0.34245518 0.18180327]\n"," [0.4837552  0.34579426 0.1704504 ]\n"," [0.47634816 0.34624618 0.17740567]\n"," ...\n"," [0.47505724 0.3436345  0.18130836]\n"," [0.49075428 0.34507975 0.16416602]\n"," [0.47702798 0.3470523  0.17591974]]\n","[0 0 0 ... 0 0 0]\n"]}]},{"cell_type":"markdown","source":["# Combined Model for Multi-Modal + Multi-Objective learning"],"metadata":{"id":"ayPsiNuCfcg4"}},{"cell_type":"markdown","source":["This block implements a combined version of Bi-RNN + CNN based models discussed in the above sections to combine both of their funcationality to train on both images and text sequences (summaries) together and train the model to predict both the objectives: Price and Type of apartment together."],"metadata":{"id":"_BjwuqAyfizX"}},{"cell_type":"code","source":["# Taking text and image inputs:\n","in_text = keras.Input(batch_shape=(None, max_len))\n","in_image = keras.Input(batch_shape=(None, 64, 64, 2))\n","\n","# Learning from the Text based on Bi-GRU Model\n","e_layer = Embedding(tokenizer.num_words, 100)(in_text)                          # Creating Embeddings layer\n","bi_gru = Bidirectional(GRU(64, activation = 'relu'))(e_layer)                   # Creating Bidirectional LSTM Layer\n","d_text = Dense(32)(bi_gru)\n","\n","# Learning from the Image features using CNN Network\n","conv1 = Conv2D(16, 3, activation = 'softmax')(in_image)\n","mxpool1 = MaxPool2D(2)(conv1)\n","d1 = Dropout(0.5)(mxpool1)\n","conv2 = Conv2D(32, 3, padding = 'same', activation = 'softmax')(d1)\n","mxpool2 = MaxPool2D(2)(conv2)\n","d2 = Dropout(0.5)(mxpool2)\n","conv3 = Conv2D(64, 3, padding = 'same', activation = 'softmax')(d2)\n","d3 = Dropout(0.5)(conv3)\n","d_img = Dense(32, activation = 'relu')(d2)\n","flat = Flatten()(d_img)\n","\n","# Finally combine both the Bi-GRU and CNN networks\n","combined = tf.concat([d_text, flat], axis=-1)\n","\n","\n","# Same as before\n","out_price = Dense(len_price, activation='relu', name='price')(combined)\n","out_type = Dense(len_type, activation='relu', name='type')(combined)\n","\n","\n","m_fin = keras.Model(inputs={'text': in_text, 'img': in_image},\n","                    outputs={'price': out_price,'type': out_type,}, name = 'Combined_Model')\n","\n","m_fin.compile(\n","\n","    optimizer=Adam(),                                   # Using Adam as optimizer\n","    loss={                                              # Settings loss computation metrics for 'price' and 'text' objectives\n","        'price': 'sparse_categorical_crossentropy',\n","        'type': 'sparse_categorical_crossentropy',\n","    },\n","    metrics={                                           # Metrics to use for evaluation during training\n","        'price': ['SparseCategoricalAccuracy'],\n","        'type': ['SparseCategoricalAccuracy'],\n","    },\n",")\n","\n","\n","m_fin.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jpShJaYBgM0c","executionInfo":{"status":"ok","timestamp":1668831384308,"user_tz":300,"elapsed":548,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"8168857a-f910-4491-fae3-638f156008c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"Combined_Model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_9 (InputLayer)           [(None, 64, 64, 2)]  0           []                               \n","                                                                                                  \n"," conv2d_7 (Conv2D)              (None, 62, 62, 16)   304         ['input_9[0][0]']                \n","                                                                                                  \n"," max_pooling2d_5 (MaxPooling2D)  (None, 31, 31, 16)  0           ['conv2d_7[0][0]']               \n","                                                                                                  \n"," dropout_6 (Dropout)            (None, 31, 31, 16)   0           ['max_pooling2d_5[0][0]']        \n","                                                                                                  \n"," conv2d_8 (Conv2D)              (None, 31, 31, 32)   4640        ['dropout_6[0][0]']              \n","                                                                                                  \n"," input_8 (InputLayer)           [(None, 100)]        0           []                               \n","                                                                                                  \n"," max_pooling2d_6 (MaxPooling2D)  (None, 15, 15, 32)  0           ['conv2d_8[0][0]']               \n","                                                                                                  \n"," embedding_4 (Embedding)        (None, 100, 100)     4000000     ['input_8[0][0]']                \n","                                                                                                  \n"," dropout_7 (Dropout)            (None, 15, 15, 32)   0           ['max_pooling2d_6[0][0]']        \n","                                                                                                  \n"," bidirectional_4 (Bidirectional  (None, 128)         63744       ['embedding_4[0][0]']            \n"," )                                                                                                \n","                                                                                                  \n"," dense_7 (Dense)                (None, 15, 15, 32)   1056        ['dropout_7[0][0]']              \n","                                                                                                  \n"," dense_6 (Dense)                (None, 32)           4128        ['bidirectional_4[0][0]']        \n","                                                                                                  \n"," flatten_2 (Flatten)            (None, 7200)         0           ['dense_7[0][0]']                \n","                                                                                                  \n"," tf.concat_2 (TFOpLambda)       (None, 7232)         0           ['dense_6[0][0]',                \n","                                                                  'flatten_2[0][0]']              \n","                                                                                                  \n"," price (Dense)                  (None, 3)            21699       ['tf.concat_2[0][0]']            \n","                                                                                                  \n"," type (Dense)                   (None, 24)           173592      ['tf.concat_2[0][0]']            \n","                                                                                                  \n","==================================================================================================\n","Total params: 4,269,163\n","Trainable params: 4,269,163\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Fit the model to begin training\n","history = m_fin.fit(\n","    x={'text': x_tr_text_id,'img': x_tr_image},\n","    y={'price': y_tr_price,'type': y_tr_type,},\n","    epochs=25,                                          # No. of epochs to train for.\n","    batch_size=128,                                      # Size of each batch for epoch\n","    validation_data=(                                   # Data used for validation to evaluate the loss\n","        {'text': x_vl_text_id,'img': x_vl_image},\n","        {'price': y_vl_price,'type': y_vl_type},),\n","    validation_split=0.15,                              # Perform validation on 20% Split of the training data\n","    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights = 'True')],\n","    verbose=1\n",")"],"metadata":{"id":"iM0vv1HZmYLC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Observation:**\n","\n","The combined model performs only slightly better, but it features considering both modalities and predict both outputs.\n","\n","Further tuning and optimization could yield better results.\n"],"metadata":{"id":"edpcGU2PJV2u"}}],"metadata":{"colab":{"collapsed_sections":["CfaTkNbAbMhe","4_ICLcP1E4AE","MU1qVkBnwJAb","W2Ld0Qh9kvPv","EifsEGsj_xPP","JXX8oog-6dAy","ayPsiNuCfcg4","J734mta7ec2i"],"provenance":[{"file_id":"1Zlw7B2PJtg7WOs7f8fM_m0WQLQKR4bKi","timestamp":1708461901246}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0b6d04620ec24cc99c32afc0f3880823":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9143a870dec54e93806b93b2666f4452","IPY_MODEL_e12422d084b44487828d727d060ad3b8","IPY_MODEL_67db9a14ece54b5bb2c352766503ff1d"],"layout":"IPY_MODEL_e3051eefa2bc4e70a768f26928976d27"}},"9143a870dec54e93806b93b2666f4452":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec0035e7a94c4d0789d7a6ad5d5aee28","placeholder":"​","style":"IPY_MODEL_70416de52849433eaee1c1489138dbec","value":"100%"}},"e12422d084b44487828d727d060ad3b8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_56491b38baf04a2a87bf175b38025740","max":7627,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2c36714bbd50490eb06229599d1ac36e","value":7627}},"67db9a14ece54b5bb2c352766503ff1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_118626f057c54accbb6f67b0a8be800e","placeholder":"​","style":"IPY_MODEL_e1475f49197f4306bd27b1e34904998e","value":" 7627/7627 [01:54&lt;00:00, 78.30it/s]"}},"e3051eefa2bc4e70a768f26928976d27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec0035e7a94c4d0789d7a6ad5d5aee28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70416de52849433eaee1c1489138dbec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"56491b38baf04a2a87bf175b38025740":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c36714bbd50490eb06229599d1ac36e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"118626f057c54accbb6f67b0a8be800e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1475f49197f4306bd27b1e34904998e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}