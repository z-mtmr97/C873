{"cells":[{"cell_type":"markdown","source":["# Setup / Data Loading"],"metadata":{"id":"wvU-85dBVIfF"}},{"cell_type":"markdown","source":["## Linking & Imports"],"metadata":{"id":"uiU40zRZqtwG"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IctK4CYP3wAy","executionInfo":{"status":"ok","timestamp":1670292878865,"user_tz":300,"elapsed":866,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"915f6169-41d5-4421-942e-fe76ccd6a794"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Install/Import required packages\n","\n","!pip install --quiet networkx                   # Package for working with network based data syructures like Graphs\n","!pip install --quiet tf2_gnn                    # Package for implementing Graphs NNs for TF2\n","\n","import numpy as np                              # for working with numerical arrays\n","from tqdm.notebook import tqdm                  # for fancy progress bar\n","import networkx as nx                           # for working with networks\n","import matplotlib.pyplot as plt                 # for matrix plots\n","from matplotlib import cm                       # for handling colourmaps for visualization\n","import random                                   # for enerating reandom numbers\n","import math                                     # modeule for mathematical formulae\n","import pandas as pd                             # pandas for working and manipulating data\n","\n","#Import models for NN training and loading dataset\n","from sklearn.model_selection import train_test_split\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import tensorflow as tf\n","from tensorflow.math import segment_mean\n","from tensorflow import keras\n","from tensorflow.keras import Input, Model\n","from tensorflow.keras.layers import Embedding, Dense\n","from tensorflow.keras.optimizers import Adam\n","from tf2_gnn.layers.gnn import GNN, GNNInput\n","\n","from tf2_gnn.layers.message_passing import *\n"],"metadata":{"id":"dNv5NKYwVT4w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a method to read the sdf file and create Graph representations\n","def read_sdf(file):\n","    with open(file, 'r') as rf:                                       # Open File to read\n","        content = rf.read()\n","    samples = content.split('$$$$')                                   # Split the lines at '$$$$' delimeter to seperate each sample (molecule data) from the file\n","\n","    def parse_sample(s):\n","        lines = s.splitlines()                                        # Split each line\n","        links = []\n","        nodes = []\n","        label = 0\n","        for l in lines:                                               # Remove the the marker from the data and add corresponding Positive/Negative label\n","            if l.strip() == '1.0':\n","                label = 1\n","            if l.strip() == '-1.0':\n","                label = 0\n","            if l.startswith('    '):                                  # Identify if the line corresposnds to a node and if found, append to node list\n","                feature = l.split()\n","                node = feature[3]\n","                nodes.append(node)\n","            elif l.startswith(' '):                                   # Identify edges from and to each node and establish links\n","                lnk = l.split()\n","                if int(lnk[0]) - 1 < len(nodes):\n","                    links.append((\n","                        int(lnk[0])-1,\n","                        int(lnk[1])-1, # zero-based index\n","                        # int(lnk[2]) ignore edge weight\n","                    ))\n","        return nodes, np.array(links), label                          # Return created nodes, links and labels to wrapping function\n","\n","    return [parse_sample(s) for s in tqdm(samples) if len(s[0]) > 0]  # Return generated graph representations to calling function\n","\n","\n","\n","# Load Train/Test dataset from drive and create a split for validation set\n","training_set = read_sdf('/content/drive/MyDrive/cisc/A6/train.sdf')\n","testing_set  = read_sdf('/content/drive/MyDrive/cisc/A6/test_x.sdf')\n","training_set, validation_set = train_test_split(training_set, test_size=0.25,)\n","\n","print(training_set[0])\n"],"metadata":{"id":"mP4yBXd4meSv","colab":{"base_uri":"https://localhost:8080/","height":353,"referenced_widgets":["67b5c79fd0ef422386f0869096cf725f","6c32a8c95d064d4b9f4e7d4f14c7fc8a","5e2f799dd0414635871b41c4ae06b169","2b8846595248472296e337bcdff3f9ad","74fd4c02c5e84558a1b05d48243bdb5c","f23d59a3fe5d42c0bfae1b1788acfe28","bb6ecdc5c81047ee8e304c496d4e18de","12554cf8294f4a14bea40f2ccc5c6976","0712dbb1cb244156a99422fb381634b1","753ca6691d3c469096e00af80a916099","68afd771402d4345b0defe9e3619c10a","052b94f489b44d0d90b0e55ba021b459","8378f79672d842049e052210d9ef353a","30a5ed803a1f43c3b940cd87439ef49d","e1388af836ea4cfc96dcd6884482563c","dcf61a7cf590472bb0140efbf88f6b3e","97f2296283724c078bfe34c3aaf097d1","3d81696172a84c55b40e5ccf6ecc1997","67b82e9e9c8a4e418ae3444117ef429a","72f79c13433a4f558e1a7e2b81d3f18e","8156b6d2b5534070b6f53a430aa39050","b74d3b38b50f465fa5b1505bb35cd9c1"]},"executionInfo":{"status":"ok","timestamp":1670292899210,"user_tz":300,"elapsed":7646,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"239e58b3-e79e-4aa5-8521-635046c6c430"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/25024 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67b5c79fd0ef422386f0869096cf725f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/12326 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"052b94f489b44d0d90b0e55ba021b459"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(['O', 'O', 'O', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C'], array([[ 0,  8],\n","       [ 1, 11],\n","       [ 1, 12],\n","       [ 2, 11],\n","       [ 3,  4],\n","       [ 3,  5],\n","       [ 3,  6],\n","       [ 4,  5],\n","       [ 4,  8],\n","       [ 5,  9],\n","       [ 6,  7],\n","       [ 6, 10],\n","       [ 7,  8],\n","       [ 7,  9],\n","       [10, 11]]), 0)\n"]}]},{"cell_type":"code","source":["# Visualize a sample from tehe loaded dataset\n","\n","# Create a rainbow schemed colourmap with equally spaced samples between 0 and 1, Used for representing the colourspace of the nodes\n","colors = cm.rainbow(np.linspace(0, 1, 50))\n","\n","\n","# Define custom function to create a visualization\n","def visualize(sample):\n","    G=nx.Graph()                                            # Cretae an empty Graph object\n","    nodes = sample[0]                                       # Fetch nodes from the passed sample of training data\n","    edges = sample[1]                                       # Fetch edges/links from the passed sample of training data\n","\n","    labeldict={}\n","    node_color=[]\n","    for i,n in enumerate(nodes):\n","        G.add_node(i)                                       # Add nodes to the graph\n","        labeldict[i]=n                                      # Add labels for atoms Carbon/Nitroen/Oxygen/Fluorine etc.\n","        node_color.append(colors[hash(n)%len(colors)])\n","\n","    for e in edges:\n","        G.add_edge(e[0], e[1])                              # Add edges between nodes\n","\n","    nx.draw(G, labels=labeldict, with_labels = True, node_color = node_color)     # Draw the Graph and plot it\n","    plt.show()\n","\n","    return G                                                 # Return Graph\n","\n","plt.clf()                                                    # Clear figure before plotting new one\n","visualize(training_set[0])                                   # Visulaise using defined function"],"metadata":{"id":"DX7iMtoBmx02","colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"status":"ok","timestamp":1670292899655,"user_tz":300,"elapsed":459,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"a9e3101d-1893-40d0-9303-829faf71eb2b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["<networkx.classes.graph.Graph at 0x7fcfd38c29a0>"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"AJeCtdi73hxH"},"source":["## Data Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xzYW367k3hxH"},"outputs":[],"source":["max_vocab = 500\n","max_len = 100\n","\n","# Build vocabulary from training set\n","all_nodes = [s[0] for s in training_set]      # Get nodes from training set\n","tokenizer = Tokenizer(num_words=max_vocab)    # Generate tokens keep a maximum of 500 words, each with a max length of 100\n","tokenizer.fit_on_texts(all_nodes)             # Create an index for vocabulary based on frequency of each word/node in the graph"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kokS7mKF3hxI"},"outputs":[],"source":["random.seed(0)                    # Initialize random number generator with seed 0, ensures reproduceability\n","\n","# Define a function to create a single mini-batch (inidividual molecule) from samples\n","def prepare_single_batch(samples):\n","    sample_nodes = [s[0] for s in samples]                              # Fetch nodes from the sample graph\n","    sample_nodes = tokenizer.texts_to_sequences(sample_nodes)           # Create a sequence of integrers to represent the nodes\n","    sample_nodes = pad_sequences(sample_nodes, padding='post')          # Add paddings to ensure sequences are the same length\n","    max_nodes_len = np.shape(sample_nodes)[1]                           # Get max length of nodes for each sample\n","    edges = [s[1]+i*max_nodes_len for i,s in enumerate(samples)]\n","    edges = [e for e in edges if len(e) > 0]                            # Generate Edges for the links between each node in the sample\n","    node_to_graph = [[i]*max_nodes_len for i in range(len(samples))]    # Generate the graph representation\n","\n","    all_nodes = np.reshape(sample_nodes, -1)\n","    all_edges = np.concatenate(edges)\n","    node_to_graph = np.reshape(node_to_graph, -1)\n","    return {                                                            # Return Graph as keys and values individual nodes, edges and the links between them\n","        'data': all_nodes,\n","        'edges': all_edges,\n","        'node2graph': node_to_graph,\n","    }, np.array([s[2] for s in samples])                                # Also return the labels for each\n","\n","\n","# Defining a method for generating a training/testing batch of 'n' minibatches\n","def gen_batch(dataset, batch_size=16, repeat=False, shuffle=True):\n","    while True:\n","        dataset = list(dataset)\n","        if shuffle:\n","            random.shuffle(dataset)\n","        l = len(dataset)\n","        for ndx in range(0, l, batch_size):                              # Prepare individual minibatches and stick them together\n","            batch_samples = dataset[ndx:min(ndx + batch_size, l)]\n","            yield prepare_single_batch(batch_samples)                    # Combine 'batch_size' no. of minibatches\n","        if not repeat:\n","            break\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hJAGGm0g3hxJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670292900133,"user_tz":300,"elapsed":5,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"8c677c5d-74e9-486c-f85e-351b0c049fca"},"outputs":[{"output_type":"stream","name":"stdout","text":["data\n","[3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 4 2 2 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0]\n","edges\n","[[  0   8]\n"," [  0  18]\n"," [  1   9]\n"," [  1  19]\n"," [  2  10]\n"," [  2  26]\n"," [  3  11]\n"," [  3  27]\n"," [  4  13]\n"," [  4  28]\n"," [  4  29]\n"," [  5  15]\n"," [  5  30]\n"," [  5  31]\n"," [  6   8]\n"," [  6  10]\n"," [  6  16]\n"," [  7   9]\n"," [  7  11]\n"," [  7  17]\n"," [  8  12]\n"," [  9  14]\n"," [ 10  20]\n"," [ 11  21]\n"," [ 12  13]\n"," [ 13  22]\n"," [ 14  15]\n"," [ 15  23]\n"," [ 16  22]\n"," [ 17  23]\n"," [ 18  20]\n"," [ 18  24]\n"," [ 19  21]\n"," [ 19  25]\n"," [ 26  32]\n"," [ 27  33]\n"," [ 32  34]\n"," [ 33  35]\n"," [ 34  36]\n"," [ 35  37]\n"," [ 36  37]\n"," [ 38  41]\n"," [ 38  45]\n"," [ 38  46]\n"," [ 39  47]\n"," [ 39  53]\n"," [ 40  50]\n"," [ 40  58]\n"," [ 40  59]\n"," [ 41  42]\n"," [ 41  43]\n"," [ 42  44]\n"," [ 42  47]\n"," [ 43  51]\n"," [ 44  48]\n"," [ 45  48]\n"," [ 46  52]\n"," [ 49  53]\n"," [ 49  54]\n"," [ 49  55]\n"," [ 50  56]\n"," [ 50  57]\n"," [ 51  52]\n"," [ 54  56]\n"," [ 55  57]\n"," [ 76  77]\n"," [ 76  78]\n"," [ 76  80]\n"," [ 76  87]\n"," [ 79  82]\n"," [ 79  83]\n"," [ 79  92]\n"," [ 80  81]\n"," [ 81  86]\n"," [ 82  85]\n"," [ 82  86]\n"," [ 83  84]\n"," [ 83  88]\n"," [ 84  85]\n"," [ 84  89]\n"," [ 86  95]\n"," [ 87  90]\n"," [ 87  91]\n"," [ 88  93]\n"," [ 89  94]\n"," [ 90  97]\n"," [ 91  98]\n"," [ 93  94]\n"," [ 96  97]\n"," [ 96  98]\n"," [ 96  99]\n"," [119 114]\n"," [114 124]\n"," [120 115]\n"," [115 124]\n"," [121 116]\n"," [116 126]\n"," [117 127]\n"," [117 130]\n"," [118 126]\n"," [119 120]\n"," [119 121]\n"," [120 123]\n"," [121 122]\n"," [122 123]\n"," [122 125]\n"," [123 127]\n"," [124 128]\n"," [124 129]\n"," [125 126]\n"," [130 131]\n"," [131 132]\n"," [131 133]\n"," [132 134]\n"," [133 135]\n"," [134 136]\n"," [135 136]]\n","node2graph\n","[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n"," 3 3 3 3]\n","label [0 0 0 0]\n"]}],"source":["# Show one created batch of samples\n","for train_batch in gen_batch(training_set, batch_size=4):\n","    for k,v in train_batch[0].items():        # Print the nodes, edges and their interlinks\n","        print(k)\n","        print(v)\n","        pass\n","    print('label', train_batch[1])            # Print the labels for the molecules in generated batch\n","    break"]},{"cell_type":"markdown","source":["# Implementing RGCN Mechanism\n"],"metadata":{"id":"YOWy9XqLBLug"}},{"cell_type":"markdown","source":["## A.\n","Implementing the built-in RGCN mechanism discussed proposed by Schlichtkrull et al. (2017) with further fine tuning and more refining."],"metadata":{"id":"JbCzgzgbCBym"}},{"cell_type":"code","source":["from tf2_gnn.layers.message_passing import RGCN\n","\n","# Create input tensors to pass to the GNN. (Added names to better analyze the output in Model Summary)\n","data = keras.Input(batch_shape=(None,), name = 'data')\n","edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32, name = 'edges')\n","node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32, name = 'n2g')\n","embeded = Embedding(tokenizer.num_words, 20, name = 'emb')(data)\n","\n","\n","# number of graphs (number of samples)\n","num_graph = tf.reduce_max(node2graph)+1\n","\n","node_embeddings = embeded\n","adjacency_lists=(edge,)\n","\n","params = RGCN.get_default_hyperparameters()                        # Working with default_params defined in message_passing.RGCN\n","params[\"hidden_dim\"] = 32\n","gnn_layer = RGCN(params)                                          # Define RGCN layer with imported params\n","gnn_out = gnn_layer(MessagePassingInput(node_embeddings, adjacency_lists))\n","\n","\n","avg = segment_mean(data=gnn_out, segment_ids=node2graph)          # Calculate the segment mean to use for prediction\n","\n","pred = Dense(1, activation='sigmoid')(avg)                        # Output layer for predictions\n","\n","# Definng the model for training\n","model = Model(\n","    inputs={\n","        'data': data,\n","        'edges': edge,\n","        'node2graph': node2graph,\n","    },\n","    outputs=pred\n",")\n","model.summary()\n","\n","\n","model.compile(                                                   # Default Optimizer to RMSProp\n","    loss='BinaryCrossentropy',                                   # Use Binary Cross Entrpy for loss calculation\n","    metrics='AUC'                                                # Use Area Under Curve for evaluating the model performance\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1DpwneM8CPOL","executionInfo":{"status":"ok","timestamp":1670291866064,"user_tz":300,"elapsed":569,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"bb7d8253-47d4-45b0-c3b6-daf3e0e5da12"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_8\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," data (InputLayer)              [(None,)]            0           []                               \n","                                                                                                  \n"," emb (Embedding)                (None, 20)           10000       ['data[0][0]']                   \n","                                                                                                  \n"," edges (InputLayer)             [(None, 2)]          0           []                               \n","                                                                                                  \n"," rgcn_5 (RGCN)                  (None, 32)           640         ['emb[0][0]',                    \n","                                                                  'edges[0][0]']                  \n","                                                                                                  \n"," n2g (InputLayer)               [(None,)]            0           []                               \n","                                                                                                  \n"," tf.math.segment_mean_8 (TFOpLa  (None, 32)          0           ['rgcn_5[0][0]',                 \n"," mbda)                                                            'n2g[0][0]']                    \n","                                                                                                  \n"," dense_8 (Dense)                (None, 1)            33          ['tf.math.segment_mean_8[0][0]'] \n","                                                                                                  \n","==================================================================================================\n","Total params: 10,673\n","Trainable params: 10,673\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["batch_size = 128                                                                 # Size of inidividual mini-batch (no. of compunds to use for each minibatch)\n","ep = 5                                                                         # No. of Epochs\n","num_batchs = math.ceil(len(training_set) / batch_size)                          # Total no. of batches for training based on total size and size of inidividual mini batch\n","num_batchs_validation = math.ceil(len(validation_set) / batch_size)             # Total no. of batches for validation\n","\n","\n","# Fit the model to begin training\n","model.fit(\n","    gen_batch(training_set, batch_size=batch_size, repeat=True),                # Generate batches for training based on b_size and passing the training set\n","    steps_per_epoch=num_batchs,                                                 # Each epoch has same steps and the no. of batches\n","    epochs=ep,\n","    validation_data=gen_batch(validation_set, batch_size=16, repeat=True),      # Generate batches for validation\n","    validation_steps=num_batchs_validation,                                     # Steps for validation\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6rs-ha-hCcfW","executionInfo":{"status":"ok","timestamp":1670292109447,"user_tz":300,"elapsed":10834,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"ff506e59-5164-4514-8bc6-585d5a6f15c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","147/147 [==============================] - 2s 15ms/step - loss: 0.1901 - auc: 0.6024 - val_loss: 0.1634 - val_auc: 0.6821\n","Epoch 2/5\n","147/147 [==============================] - 2s 14ms/step - loss: 0.1883 - auc: 0.6103 - val_loss: 0.1554 - val_auc: 0.5845\n","Epoch 3/5\n","147/147 [==============================] - 2s 14ms/step - loss: 0.1875 - auc: 0.6162 - val_loss: 0.1949 - val_auc: 0.6380\n","Epoch 4/5\n","147/147 [==============================] - 2s 14ms/step - loss: 0.1867 - auc: 0.6214 - val_loss: 0.2068 - val_auc: 0.6795\n","Epoch 5/5\n","147/147 [==============================] - 2s 15ms/step - loss: 0.1858 - auc: 0.6274 - val_loss: 0.1523 - val_auc: 0.7057\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8694323c40>"]},"metadata":{},"execution_count":49}]},{"cell_type":"markdown","source":["**Observation:**\n","\n","The results are almost inline with the default params, likely since it also implements RGCN albeit with a different set of hyperparams.\n","\n","Since this method of manually initialting a call to message_passing class is tedious, the next iterations will use similar method as the template.\n"],"metadata":{"id":"zYEOgvExJ2Qm"}},{"cell_type":"markdown","source":["## B.\n","\n","Next Iter:\n","\n","* Deeper GCN layers\n","* More hidden layers\n","\n","To see if it makes any difference before further tuning other default parameters.\n"],"metadata":{"id":"P2D8QwvvLH9R"}},{"cell_type":"code","source":["# Create input tensors to pass to the GNN. (Added names to better analyze the output in Model Summary)\n","data = keras.Input(batch_shape=(None,), name = 'data')\n","edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32, name = 'edges')\n","node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32, name = 'n2g')\n","embeded = Embedding(tokenizer.num_words, 20, name = 'emb')(data)\n","\n","\n","# number of graphs (number of samples)\n","num_graph = tf.reduce_max(node2graph)+1\n","\n","# Defining the tuple to pass as an input to the GNN\n","gnn_input = GNNInput(\n","    node_features=embeded,                                        # The initial node features are the input embeddings\n","    adjacency_lists=(edge,),                                      # The adjacency list is teh tensor of edges\n","    node_to_graph_map=node2graph,                                 # Pass the node to graph map\n","    num_graphs=num_graph,                                         # The input works with given no. of samples\n",")\n","\n","\n","params = GNN.get_default_hyperparameters(mp_style='RGCN')         # Set Message Passing Style = RGCN\n","params[\"hidden_dim\"] = 64                                         # Set dimension of hidden layer for convolutions to 64\n","params[\"num_layers\"] = 8                                          # Set number of layers to 8\n","gnn_layer = GNN(params)\n","gnn_out = gnn_layer(gnn_input)\n","\n","\n","avg = segment_mean(data=gnn_out, segment_ids=node2graph)          # Calculate the segment mean to use for prediction\n","\n","pred = Dense(1, activation='sigmoid')(avg)                        # Output layer for predictions\n","\n","# Definng the model for training\n","model = Model(\n","    inputs={\n","        'data': data,\n","        'edges': edge,\n","        'node2graph': node2graph,\n","    },\n","    outputs=pred\n",")\n","model.summary()\n","\n","\n","model.compile(                                                   # Default Optimizer to RMSProp\n","    loss='BinaryCrossentropy',                                   # Use Binary Cross Entrpy for loss calculation\n","    metrics='AUC'                                                # Use Area Under Curve for evaluating the model performance\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fNf36tEbLDMT","executionInfo":{"status":"ok","timestamp":1670293075398,"user_tz":300,"elapsed":1683,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"0c49ae79-6b40-4f3d-9a08-9a891028f373"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_2\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," n2g (InputLayer)               [(None,)]            0           []                               \n","                                                                                                  \n"," data (InputLayer)              [(None,)]            0           []                               \n","                                                                                                  \n"," tf.math.reduce_max_2 (TFOpLamb  ()                  0           ['n2g[0][0]']                    \n"," da)                                                                                              \n","                                                                                                  \n"," emb (Embedding)                (None, 20)           10000       ['data[0][0]']                   \n","                                                                                                  \n"," edges (InputLayer)             [(None, 2)]          0           []                               \n","                                                                                                  \n"," tf.__operators__.add_2 (TFOpLa  ()                  0           ['tf.math.reduce_max_2[0][0]']   \n"," mbda)                                                                                            \n","                                                                                                  \n"," gnn_2 (GNN)                    (None, 64)           187520      ['emb[0][0]',                    \n","                                                                  'edges[0][0]',                  \n","                                                                  'n2g[0][0]',                    \n","                                                                  'tf.__operators__.add_2[0][0]'] \n","                                                                                                  \n"," tf.math.segment_mean_2 (TFOpLa  (None, 64)          0           ['gnn_2[0][0]',                  \n"," mbda)                                                            'n2g[0][0]']                    \n","                                                                                                  \n"," dense_2 (Dense)                (None, 1)            65          ['tf.math.segment_mean_2[0][0]'] \n","                                                                                                  \n","==================================================================================================\n","Total params: 197,585\n","Trainable params: 197,585\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["batch_size = 128                                                                 # Size of inidividual mini-batch (no. of compunds to use for each minibatch)\n","ep = 5                                                                         # No. of Epochs\n","num_batchs = math.ceil(len(training_set) / batch_size)                          # Total no. of batches for training based on total size and size of inidividual mini batch\n","num_batchs_validation = math.ceil(len(validation_set) / batch_size)             # Total no. of batches for validation\n","\n","\n","# Fit the model to begin training\n","model.fit(\n","    gen_batch(training_set, batch_size=batch_size, repeat=True),                # Generate batches for training based on b_size and passing the training set\n","    steps_per_epoch=num_batchs,                                                 # Each epoch has same steps and the no. of batches\n","    epochs=ep,\n","    validation_data=gen_batch(validation_set, batch_size=16, repeat=True),      # Generate batches for validation\n","    validation_steps=num_batchs_validation,                                     # Steps for validation\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wseQEQWdMPyU","executionInfo":{"status":"ok","timestamp":1670293595168,"user_tz":300,"elapsed":515948,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"bd327542-3947-4baf-e367-70318b0be400"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","147/147 [==============================] - 99s 580ms/step - loss: 0.2817 - auc: 0.3991 - val_loss: 0.1820 - val_auc: 0.3937\n","Epoch 2/5\n","147/147 [==============================] - 94s 643ms/step - loss: 0.2063 - auc: 0.5596 - val_loss: 0.2327 - val_auc: 0.4980\n","Epoch 3/5\n","147/147 [==============================] - 88s 595ms/step - loss: 0.1966 - auc: 0.6156 - val_loss: 0.2082 - val_auc: 0.7035\n","Epoch 4/5\n","147/147 [==============================] - 92s 622ms/step - loss: 0.1950 - auc: 0.6216 - val_loss: 0.2054 - val_auc: 0.5629\n","Epoch 5/5\n","147/147 [==============================] - 95s 649ms/step - loss: 0.1903 - auc: 0.6414 - val_loss: 0.1985 - val_auc: 0.7082\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fcfc103e9a0>"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["## C.\n","Further changing the parameters:\n","* Added dropout\n","* hanged optimizer to Adam\n","* Changed initial_layer_activation\n","* Changed global_exchange_mode"],"metadata":{"id":"8ueKdBj7POUB"}},{"cell_type":"code","source":["from tensorflow.keras.optimizers import Adam\n","\n","\n","# Create input tensors to pass to the GNN. (Added names to better analyze the output in Model Summary)\n","data = keras.Input(batch_shape=(None,), name = 'data')\n","edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32, name = 'edges')\n","node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32, name = 'n2g')\n","embeded = Embedding(tokenizer.num_words, 20, name = 'emb')(data)\n","\n","\n","# number of graphs (number of samples)\n","num_graph = tf.reduce_max(node2graph)+1\n","\n","# Defining the tuple to pass as an input to the GNN\n","gnn_input = GNNInput(\n","    node_features=embeded,                                        # The initial node features are the input embeddings\n","    adjacency_lists=(edge,),                                      # The adjacency list is teh tensor of edges\n","    node_to_graph_map=node2graph,                                 # Pass the node to graph map\n","    num_graphs=num_graph,                                         # The input works with given no. of samples\n",")\n","\n","\n","params = GNN.get_default_hyperparameters(mp_style='RGCN')         # Set Message Passing Style = RGCN\n","params[\"hidden_dim\"] = 32                                         # Set dimension of hidden layer for convolutions to 64\n","params[\"num_layers\"] = 6                                          # Set number of layers to 8\n","params[\"global_exchange_mode\"] = \"mlp\"\n","params[\"initial_node_representation_activation\"] = \"relu\"\n","params[\"layer_input_dropout_rate\"] = 0.2\n","gnn_layer = GNN(params)\n","gnn_out = gnn_layer(gnn_input)\n","\n","\n","avg = segment_mean(data=gnn_out, segment_ids=node2graph)          # Calculate the segment mean to use for prediction\n","\n","pred = Dense(1, activation='sigmoid')(avg)                        # Output layer for predictions\n","\n","# Definng the model for training\n","model = Model(\n","\n","    inputs={\n","        'data': data,\n","        'edges': edge,\n","        'node2graph': node2graph,\n","    },\n","    outputs=pred\n",")\n","model.summary()\n","\n","\n","model.compile(\n","    optimizer = Adam(learning_rate=0.001, amsgrad = True),          # Optimizer set to Adam with AmsGrad\n","    loss='BinaryCrossentropy',\n","    metrics='AUC'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KrpQqdcgPLPD","executionInfo":{"status":"ok","timestamp":1670294940833,"user_tz":300,"elapsed":1350,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"88c68b41-f599-49f6-a586-9a1b7f7a0f15"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_6\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," n2g (InputLayer)               [(None,)]            0           []                               \n","                                                                                                  \n"," data (InputLayer)              [(None,)]            0           []                               \n","                                                                                                  \n"," tf.math.reduce_max_7 (TFOpLamb  ()                  0           ['n2g[0][0]']                    \n"," da)                                                                                              \n","                                                                                                  \n"," emb (Embedding)                (None, 20)           10000       ['data[0][0]']                   \n","                                                                                                  \n"," edges (InputLayer)             [(None, 2)]          0           []                               \n","                                                                                                  \n"," tf.__operators__.add_7 (TFOpLa  ()                  0           ['tf.math.reduce_max_7[0][0]']   \n"," mbda)                                                                                            \n","                                                                                                  \n"," gnn_7 (GNN)                    (None, 32)           34688       ['emb[0][0]',                    \n","                                                                  'edges[0][0]',                  \n","                                                                  'n2g[0][0]',                    \n","                                                                  'tf.__operators__.add_7[0][0]'] \n","                                                                                                  \n"," tf.math.segment_mean_7 (TFOpLa  (None, 32)          0           ['gnn_7[0][0]',                  \n"," mbda)                                                            'n2g[0][0]']                    \n","                                                                                                  \n"," dense_7 (Dense)                (None, 1)            33          ['tf.math.segment_mean_7[0][0]'] \n","                                                                                                  \n","==================================================================================================\n","Total params: 44,721\n","Trainable params: 44,721\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["batch_size = 128                                                                 # Size of inidividual mini-batch (no. of compunds to use for each minibatch)\n","ep = 5                                                                         # No. of Epochs\n","num_batchs = math.ceil(len(training_set) / batch_size)                          # Total no. of batches for training based on total size and size of inidividual mini batch\n","num_batchs_validation = math.ceil(len(validation_set) / batch_size)             # Total no. of batches for validation\n","\n","\n","# Fit the model to begin training\n","model.fit(\n","    gen_batch(training_set, batch_size=batch_size, repeat=True),                # Generate batches for training based on b_size and passing the training set\n","    steps_per_epoch=num_batchs,                                                 # Each epoch has same steps and the no. of batches\n","    epochs=ep,\n","    validation_data=gen_batch(validation_set, batch_size=16, repeat=True),      # Generate batches for validation\n","    validation_steps=num_batchs_validation,                                     # Steps for validation\n",")"],"metadata":{"id":"ol-6Uob-Qc46"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Implementing GINConv"],"metadata":{"id":"sF5PedDaSKtS"}},{"cell_type":"markdown","source":["## A.\n","Xu et al. (2018) [1] proposed a method to learn non-linear representations during aggregation which helps further express the interaction between neighbouring nodes.\n","\n","[1] Xu, K., Hu, W., Leskovec, J., & Jegelka, S. (2018). How powerful are graph neural networks?. arXiv preprint arXiv:1810.00826.\n","\n","Ref [https://towardsdatascience.com/recent-advances-in-graph-convolutional-network-gcn-9166b27969e5]\n","\n","* Default Implementation to see base performance"],"metadata":{"id":"HchvmZVFTBGS"}},{"cell_type":"code","source":["\n","# Create input tensors to pass to the GNN. (Added names to better analyze the output in Model Summary)\n","data = keras.Input(batch_shape=(None,), name = 'data')\n","edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32, name = 'edges')\n","node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32, name = 'n2g')\n","embeded = Embedding(tokenizer.num_words, 20, name = 'emb')(data)\n","\n","\n","# number of graphs (number of samples)\n","num_graph = tf.reduce_max(node2graph)+1\n","\n","# Defining the tuple to pass as an input to the GNN\n","gnn_input = GNNInput(\n","    node_features=embeded,                                        # The initial node features are the input embeddings\n","    adjacency_lists=(edge,),                                      # The adjacency list is teh tensor of edges\n","    node_to_graph_map=node2graph,                                 # Pass the node to graph map\n","    num_graphs=num_graph,                                         # The input works with given no. of samples\n",")\n","\n","\n","params = GNN.get_default_hyperparameters(mp_style='RGIN')         # Set Message Passing Style = GINConv named as RGIN in the library\n","params[\"hidden_dim\"] = 32\n","gnn_layer = GNN(params)\n","gnn_out = gnn_layer(gnn_input)\n","\n","\n","avg = segment_mean(data=gnn_out, segment_ids=node2graph)          # Calculate the segment mean to use for prediction\n","\n","pred = Dense(1, activation='sigmoid')(avg)                        # Output layer for predictions\n","\n","# Definng the model for training\n","mgin = Model(\n","    inputs={\n","        'data': data,\n","        'edges': edge,\n","        'node2graph': node2graph,\n","    },\n","    outputs=pred,\n","    name = \"GIN\"\n",")\n","mgin.summary()\n","\n","# Same as before\n","mgin.compile(\n","    optimizer = Adam(learning_rate=0.001, amsgrad = True),\n","    loss='BinaryCrossentropy',\n","    metrics='AUC'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"7xFRvGbSSRZ5","executionInfo":{"status":"error","timestamp":1708461852549,"user_tz":300,"elapsed":346,"user":{"displayName":"Tufail Malik","userId":"06396934256766346901"}},"outputId":"71d6e718-b644-416c-dc5f-6e6c1942fcd1"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'keras' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-74a98e0797fc>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create input tensors to pass to the GNN. (Added names to better analyze the output in Model Summary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0medge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'edges'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnode2graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'n2g'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0membeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'emb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"]}]},{"cell_type":"code","source":["batch_size = 64                                                                 # Size of inidividual mini-batch (no. of compunds to use for each minibatch)\n","ep = 5                                                                         # No. of Epochs\n","num_batchs = math.ceil(len(training_set) / batch_size)                          # Total no. of batches for training based on total size and size of inidividual mini batch\n","num_batchs_validation = math.ceil(len(validation_set) / batch_size)             # Total no. of batches for validation\n","\n","\n","# Fit the model to begin training\n","mgin.fit(\n","    gen_batch(training_set, batch_size=batch_size, repeat=True),                # Generate batches for training based on b_size and passing the training set\n","    steps_per_epoch=num_batchs,                                                 # Each epoch has same steps and the no. of batches\n","    epochs=ep,\n","    validation_data=gen_batch(validation_set, batch_size=16, repeat=True),      # Generate batches for validation\n","    validation_steps=num_batchs_validation,                                     # Steps for validation\n",")"],"metadata":{"id":"ehC2lqtFVye7","executionInfo":{"status":"aborted","timestamp":1708461852551,"user_tz":300,"elapsed":7,"user":{"displayName":"Tufail Malik","userId":"06396934256766346901"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generate submission from predictions since training results look promising\n","# Predict the labels on testing dataset to find how good the model performs.\n","# y_pred = mgin.predict(\n","#     gen_batch(testing_set, batch_size=16, shuffle=False)                     #  Create slices of the Test dataset to generate batches for prediction\n","# )\n","# y_pred = np.reshape(y_pred, -1)                                              # Reshape the data to 1D, also to use for generating csv submissions\n","\n","# submission = pd.DataFrame({'label':y_pred})\n","# submission.index.name = 'id'\n","# submission.to_csv('/content/drive/MyDrive/cisc/A6/S-GIN.csv')"],"metadata":{"id":"MfisO0WYZ86J","executionInfo":{"status":"aborted","timestamp":1708461852552,"user_tz":300,"elapsed":7,"user":{"displayName":"Tufail Malik","userId":"06396934256766346901"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Observation**:\n","\n","Higher AUC as compared to previous iterations.\n","\n","With more training and further tuning, it could be more promising.\n","\n","However, in the interest of time, the number of epochs are kept low to demonstarte a proof of concept."],"metadata":{"id":"oIHaflkRWQfD"}},{"cell_type":"markdown","source":["## B.\n","Further Tuning GINConv\n","\n","* More layers\n","* Dropout\n","* Changed no. of MLP for GIN\n","* Changed Dropout for GLobal_exchange"],"metadata":{"id":"fWJ2iW5OWeOm"}},{"cell_type":"code","source":["\n","# Create input tensors to pass to the GNN. (Added names to better analyze the output in Model Summary)\n","data = keras.Input(batch_shape=(None,), name = 'data')\n","edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32, name = 'edges')\n","node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32, name = 'n2g')\n","embeded = Embedding(tokenizer.num_words, 20, name = 'emb')(data)\n","\n","\n","# number of graphs (number of samples)\n","num_graph = tf.reduce_max(node2graph)+1\n","\n","# Defining the tuple to pass as an input to the GNN\n","gnn_input = GNNInput(\n","    node_features=embeded,                                        # The initial node features are the input embeddings\n","    adjacency_lists=(edge,),                                      # The adjacency list is teh tensor of edges\n","    node_to_graph_map=node2graph,                                 # Pass the node to graph map\n","    num_graphs=num_graph,                                         # The input works with given no. of samples\n",")\n","\n","\n","params = GNN.get_default_hyperparameters(mp_style='RGIN')         # Set Message Passing Style = GINConv named as RGIN in the library\n","params[\"hidden_dim\"] = 64\n","params[\"num_layers\"] = 6                                          # Changing hidden dim and num_layer\n","params[\"num_edge_MLP_hidden_layers\"] = 2                          # Changing number of hidden layers for GIN MLP\n","params[\"layer_input_dropout_rate\"] = 0.25                         # Added dropout to input layer\n","params[\"global_exchange_dropout_rate\"] = 0.25                     # Increasing dropout for global_exchg\n","gnn_layer = GNN(params)\n","gnn_out = gnn_layer(gnn_input)\n","\n","\n","avg = segment_mean(data=gnn_out, segment_ids=node2graph)          # Calculate the segment mean to use for prediction\n","\n","pred = Dense(1, activation='sigmoid')(avg)                        # Output layer for predictions\n","\n","# Definng the model for training\n","mgin2 = Model(\n","    inputs={\n","        'data': data,\n","        'edges': edge,\n","        'node2graph': node2graph,\n","    },\n","    outputs=pred,\n","    name = \"GIN-2\"\n",")\n","mgin2.summary()\n","\n","# Same as before\n","mgin2.compile(\n","    optimizer = Adam(learning_rate=0.001, amsgrad = True),\n","    loss='BinaryCrossentropy',\n","    metrics='AUC'\n",")"],"metadata":{"id":"iuOh1J0NYFaA","executionInfo":{"status":"aborted","timestamp":1708461852552,"user_tz":300,"elapsed":7,"user":{"displayName":"Tufail Malik","userId":"06396934256766346901"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 64                                                                 # Size of inidividual mini-batch (no. of compunds to use for each minibatch)\n","ep = 5                                                                         # No. of Epochs\n","num_batchs = math.ceil(len(training_set) / batch_size)                          # Total no. of batches for training based on total size and size of inidividual mini batch\n","num_batchs_validation = math.ceil(len(validation_set) / batch_size)             # Total no. of batches for validation\n","\n","\n","# Fit the model to begin training\n","mgin2.fit(\n","    gen_batch(training_set, batch_size=batch_size, repeat=True),                # Generate batches for training based on b_size and passing the training set\n","    steps_per_epoch=num_batchs,                                                 # Each epoch has same steps and the no. of batches\n","    epochs=ep,\n","    validation_data=gen_batch(validation_set, batch_size=16, repeat=True),      # Generate batches for validation\n","    validation_steps=num_batchs_validation,                                     # Steps for validation\n",")"],"metadata":{"id":"c6pfySlxYn9o","executionInfo":{"status":"aborted","timestamp":1708461852552,"user_tz":300,"elapsed":7,"user":{"displayName":"Tufail Malik","userId":"06396934256766346901"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Implementing GAT\n","\n","\n"],"metadata":{"id":"Ar4yMyGqbQWo"}},{"cell_type":"markdown","source":["## A.\n","In the paper [2], the authors create a novel architecture that utilizes masked-self-attention layers to imrpove the performance of normal GCNs. This is done by adding an attention coeffecient during aggregation which helps attend over the features of neighboring nodes.\n","\n","[2] Velikovi, P., Cucurull, G., Casanova, A., Romero, A., Lio, P., & Bengio, Y. (2017). Graph attention networks. arXiv preprint arXiv:1710.10903."],"metadata":{"id":"Ds1c1IbAdnCX"}},{"cell_type":"code","source":["\n","# Create input tensors to pass to the GNN. (Added names to better analyze the output in Model Summary)\n","data = keras.Input(batch_shape=(None,), name = 'data')\n","edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32, name = 'edges')\n","node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32, name = 'n2g')\n","embeded = Embedding(tokenizer.num_words, 20, name = 'emb')(data)\n","\n","\n","# number of graphs (number of samples)\n","num_graph = tf.reduce_max(node2graph)+1\n","\n","# Defining the tuple to pass as an input to the GNN\n","gnn_input = GNNInput(\n","    node_features=embeded,                                        # The initial node features are the input embeddings\n","    adjacency_lists=(edge,),                                      # The adjacency list is teh tensor of edges\n","    node_to_graph_map=node2graph,                                 # Pass the node to graph map\n","    num_graphs=num_graph,                                         # The input works with given no. of samples\n",")\n","\n","\n","params = GNN.get_default_hyperparameters(mp_style='RGAT')         # Set Message Passing Style = GAT based GCN named as RGAT in the library\n","params[\"hidden_dim\"] = 32\n","params[\"num_heads\"] = 2                                           # GAT requires the hidden_dim be a multiple of num_heads. Default = 3\n","gnn_layer = GNN(params)\n","gnn_out = gnn_layer(gnn_input)\n","\n","\n","avg = segment_mean(data=gnn_out, segment_ids=node2graph)          # Calculate the segment mean to use for prediction\n","\n","pred = Dense(1, activation='sigmoid')(avg)                        # Output layer for predictions\n","\n","# Definng the model for training\n","mgat = Model(\n","    inputs={\n","        'data': data,\n","        'edges': edge,\n","        'node2graph': node2graph,\n","    },\n","    outputs=pred,\n","    name = \"GAT-GCN\"\n",")\n","mgat.summary()\n","\n","# Same as before\n","mgat.compile(\n","    optimizer = Adam(learning_rate=0.001, amsgrad = True),\n","    loss='BinaryCrossentropy',\n","    metrics='AUC'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q30oZ3r_euFh","executionInfo":{"status":"ok","timestamp":1670297978026,"user_tz":300,"elapsed":898,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"fc3e2467-5913-4f2e-cdee-c865b3660ed5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"GAT-GCN\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," n2g (InputLayer)               [(None,)]            0           []                               \n","                                                                                                  \n"," data (InputLayer)              [(None,)]            0           []                               \n","                                                                                                  \n"," tf.math.reduce_max_25 (TFOpLam  ()                  0           ['n2g[0][0]']                    \n"," bda)                                                                                             \n","                                                                                                  \n"," emb (Embedding)                (None, 20)           10000       ['data[0][0]']                   \n","                                                                                                  \n"," edges (InputLayer)             [(None, 2)]          0           []                               \n","                                                                                                  \n"," tf.__operators__.add_25 (TFOpL  ()                  0           ['tf.math.reduce_max_25[0][0]']  \n"," ambda)                                                                                           \n","                                                                                                  \n"," gnn_25 (GNN)                   (None, 32)           22720       ['emb[0][0]',                    \n","                                                                  'edges[0][0]',                  \n","                                                                  'n2g[0][0]',                    \n","                                                                  'tf.__operators__.add_25[0][0]']\n","                                                                                                  \n"," tf.math.segment_mean_22 (TFOpL  (None, 32)          0           ['gnn_25[0][0]',                 \n"," ambda)                                                           'n2g[0][0]']                    \n","                                                                                                  \n"," dense_22 (Dense)               (None, 1)            33          ['tf.math.segment_mean_22[0][0]']\n","                                                                                                  \n","==================================================================================================\n","Total params: 32,753\n","Trainable params: 32,753\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["batch_size = 64                                                                 # Size of inidividual mini-batch (no. of compunds to use for each minibatch)\n","ep = 5                                                                         # No. of Epochs\n","num_batchs = math.ceil(len(training_set) / batch_size)                          # Total no. of batches for training based on total size and size of inidividual mini batch\n","num_batchs_validation = math.ceil(len(validation_set) / batch_size)             # Total no. of batches for validation\n","\n","\n","# Fit the model to begin training\n","mgat.fit(\n","    gen_batch(training_set, batch_size=batch_size, repeat=True),                # Generate batches for training based on b_size and passing the training set\n","    steps_per_epoch=num_batchs,                                                 # Each epoch has same steps and the no. of batches\n","    epochs=ep,\n","    validation_data=gen_batch(validation_set, batch_size=16, repeat=True),      # Generate batches for validation\n","    validation_steps=num_batchs_validation,                                     # Steps for validation\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JUrKCEN0f6BN","executionInfo":{"status":"ok","timestamp":1670298105684,"user_tz":300,"elapsed":121980,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"afcddb3f-0107-455a-bea3-bebd2d80035e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_1_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/GatherV2_1_grad/Reshape:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_1_grad/Cast:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/GatherV2_grad/Reshape:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_grad/Cast:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_3_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_3_grad/Identity:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/cond_3_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/concat_3:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/concat_2:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/rgat_2/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_1_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_1_grad/Identity:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/cond_1_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/rgat/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/rgat/embedding_lookup_grad/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/rgat/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/rgat/embedding_lookup_1_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/rgat/embedding_lookup_1_grad/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/rgat/embedding_lookup_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["294/294 [==============================] - 28s 79ms/step - loss: 0.3057 - auc: 0.4314 - val_loss: 0.2314 - val_auc: 0.6570\n","Epoch 2/5\n","294/294 [==============================] - 24s 81ms/step - loss: 0.1954 - auc: 0.6091 - val_loss: 0.1765 - val_auc: 0.7027\n","Epoch 3/5\n","294/294 [==============================] - 24s 81ms/step - loss: 0.1874 - auc: 0.6551 - val_loss: 0.2056 - val_auc: 0.6414\n","Epoch 4/5\n","294/294 [==============================] - 23s 79ms/step - loss: 0.1824 - auc: 0.6846 - val_loss: 0.2049 - val_auc: 0.6784\n","Epoch 5/5\n","294/294 [==============================] - 23s 79ms/step - loss: 0.1827 - auc: 0.6806 - val_loss: 0.1845 - val_auc: 0.7147\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fcfc5a8f8e0>"]},"metadata":{},"execution_count":42}]},{"cell_type":"markdown","source":["**Observation**\n","\n","Very Similar results to base run of GINConv, and val_loss also follows similar trend, albeit the loss is less.\n","\n","\n","\n"],"metadata":{"id":"YlfvXtULgy2A"}},{"cell_type":"markdown","source":["## B.\n","\n","Adding fine tuning of paramaters to GAT to see imrpovement in performance/effecient training"],"metadata":{"id":"H6zdyVRQiVVo"}},{"cell_type":"code","source":["\n","# Create input tensors to pass to the GNN. (Added names to better analyze the output in Model Summary)\n","data = keras.Input(batch_shape=(None,), name = 'data')\n","edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32, name = 'edges')\n","node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32, name = 'n2g')\n","embeded = Embedding(tokenizer.num_words, 20, name = 'emb')(data)\n","\n","\n","# number of graphs (number of samples)\n","num_graph = tf.reduce_max(node2graph)+1\n","\n","# Defining the tuple to pass as an input to the GNN\n","gnn_input = GNNInput(\n","    node_features=embeded,                                        # The initial node features are the input embeddings\n","    adjacency_lists=(edge,),                                      # The adjacency list is teh tensor of edges\n","    node_to_graph_map=node2graph,                                 # Pass the node to graph map\n","    num_graphs=num_graph,                                         # The input works with given no. of samples\n",")\n","\n","\n","params = GNN.get_default_hyperparameters(mp_style='RGAT')         # Set Message Passing Style = GAT based GCN named as RGAT in the library\n","params[\"hidden_dim\"] = 40\n","params[\"num_heads\"] = 4                                           # GAT requires the hidden_dim be a multiple of num_heads. Default = 3\n","params[\"num_layers\"] = 6\n","params[\"layer_input_dropout_rate\"] = 0.25\n","params[\"initial_node_representation_activation\"] = \"relu\"\n","params[\"dense_intermediate_layer_activation\"] = \"relu\"\n","gnn_layer = GNN(params)\n","gnn_out = gnn_layer(gnn_input)\n","\n","\n","avg = segment_mean(data=gnn_out, segment_ids=node2graph)          # Calculate the segment mean to use for prediction\n","\n","pred = Dense(1, activation='sigmoid')(avg)                        # Output layer for predictions\n","\n","# Definng the model for training\n","mgat2 = Model(\n","    inputs={\n","        'data': data,\n","        'edges': edge,\n","        'node2graph': node2graph,\n","    },\n","    outputs=pred,\n","    name = \"GAT2-GCN\"\n",")\n","mgat2.summary()\n","\n","# Same as before\n","mgat2.compile(\n","    optimizer = Adam(learning_rate=0.001, amsgrad = True),\n","    loss='BinaryCrossentropy',\n","    metrics='AUC'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vpnea5cUiirq","executionInfo":{"status":"ok","timestamp":1670298880269,"user_tz":300,"elapsed":1658,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"2b756c4a-8cec-4132-a006-b34ef51f4288"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"GAT2-GCN\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," n2g (InputLayer)               [(None,)]            0           []                               \n","                                                                                                  \n"," data (InputLayer)              [(None,)]            0           []                               \n","                                                                                                  \n"," tf.math.reduce_max_32 (TFOpLam  ()                  0           ['n2g[0][0]']                    \n"," bda)                                                                                             \n","                                                                                                  \n"," emb (Embedding)                (None, 20)           10000       ['data[0][0]']                   \n","                                                                                                  \n"," edges (InputLayer)             [(None, 2)]          0           []                               \n","                                                                                                  \n"," tf.__operators__.add_32 (TFOpL  ()                  0           ['tf.math.reduce_max_32[0][0]']  \n"," ambda)                                                                                           \n","                                                                                                  \n"," gnn_32 (GNN)                   (None, 40)           59360       ['emb[0][0]',                    \n","                                                                  'edges[0][0]',                  \n","                                                                  'n2g[0][0]',                    \n","                                                                  'tf.__operators__.add_32[0][0]']\n","                                                                                                  \n"," tf.math.segment_mean_29 (TFOpL  (None, 40)          0           ['gnn_32[0][0]',                 \n"," ambda)                                                           'n2g[0][0]']                    \n","                                                                                                  \n"," dense_29 (Dense)               (None, 1)            41          ['tf.math.segment_mean_29[0][0]']\n","                                                                                                  \n","==================================================================================================\n","Total params: 69,401\n","Trainable params: 69,401\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["batch_size = 64                                                                 # Size of inidividual mini-batch (no. of compunds to use for each minibatch)\n","ep = 5                                                                         # No. of Epochs\n","num_batchs = math.ceil(len(training_set) / batch_size)                          # Total no. of batches for training based on total size and size of inidividual mini batch\n","num_batchs_validation = math.ceil(len(validation_set) / batch_size)             # Total no. of batches for validation\n","\n","\n","# Fit the model to begin training\n","mgat2.fit(\n","    gen_batch(training_set, batch_size=batch_size, repeat=True),                # Generate batches for training based on b_size and passing the training set\n","    steps_per_epoch=num_batchs,                                                 # Each epoch has same steps and the no. of batches\n","    epochs=ep,\n","    validation_data=gen_batch(validation_set, batch_size=16, repeat=True),      # Generate batches for validation\n","    validation_steps=num_batchs_validation,                                     # Steps for validation\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n15dhBk-jgvy","executionInfo":{"status":"ok","timestamp":1670299168566,"user_tz":300,"elapsed":285517,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"1505baa3-0a86-46c1-8d36-a8c35f4f035f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_5_grad/gradients/grad_ys_0_indices:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_5_grad/gradients/grad_ys_0_values:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/cond_5_grad/gradients/grad_ys_0_shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_5_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_5_grad/Identity:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/cond_5_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/concat_3:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/concat_2:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/rgat_4/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_3_grad/gradients/grad_ys_0_indices:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_3_grad/gradients/grad_ys_0_values:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/cond_3_grad/gradients/grad_ys_0_shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_3_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_3_grad/Identity:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/cond_3_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/concat_7:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/concat_6:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/rgat_2/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_1_grad/gradients/grad_ys_0_indices:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_1_grad/gradients/grad_ys_0_values:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/cond_1_grad/gradients/grad_ys_0_shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_1_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_1_grad/Identity:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/cond_1_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/rgat/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/rgat/embedding_lookup_grad/Reshape:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/rgat/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/rgat/embedding_lookup_1_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/rgat/embedding_lookup_1_grad/Reshape:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/rgat/embedding_lookup_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["294/294 [==============================] - 64s 188ms/step - loss: 0.2862 - auc: 0.4902 - val_loss: 0.2679 - val_auc: 0.6849\n","Epoch 2/5\n","294/294 [==============================] - 55s 186ms/step - loss: 0.1977 - auc: 0.5960 - val_loss: 0.1736 - val_auc: 0.7394\n","Epoch 3/5\n","294/294 [==============================] - 60s 203ms/step - loss: 0.1913 - auc: 0.6415 - val_loss: 0.1984 - val_auc: 0.6455\n","Epoch 4/5\n","294/294 [==============================] - 53s 181ms/step - loss: 0.1868 - auc: 0.6689 - val_loss: 0.2185 - val_auc: 0.6427\n","Epoch 5/5\n","294/294 [==============================] - 53s 181ms/step - loss: 0.1837 - auc: 0.6822 - val_loss: 0.1775 - val_auc: 0.7281\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fcfc37ba4f0>"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["# Generate submission from predictions since training results look promising\n","# Predict the labels on testing dataset to find how good the model performs.\n","y_pred = mgat2.predict(\n","    gen_batch(testing_set, batch_size=16, shuffle=False)                     #  Create slices of the Test dataset to generate batches for prediction\n",")\n","y_pred = np.reshape(y_pred, -1)                                              # Reshape the data to 1D, also to use for generating csv submissions\n","\n","submission = pd.DataFrame({'label':y_pred})\n","submission.index.name = 'id'\n","submission.to_csv('/content/drive/MyDrive/cisc/A6/S-GAT2.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sFS2uhEKmADt","executionInfo":{"status":"ok","timestamp":1670299344353,"user_tz":300,"elapsed":21488,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"b6ac3938-88d7-43c4-be92-59c979b67073"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["771/771 [==============================] - 12s 15ms/step\n"]}]},{"cell_type":"markdown","source":["**Observation**\n","\n","The finetuned GAT model has one of the lowest val_loss and a really good auc score.\n","This confirms the claims authors make in the paper about GATs adding more performance to base GCNs."],"metadata":{"id":"u3e2WzaBlytD"}},{"cell_type":"markdown","source":["# Implementing Extended GCN with FiLM"],"metadata":{"id":"GcY3sDY2m4K7"}},{"cell_type":"markdown","source":["## A.\n","\n","This approach is based on [3]. The authors further the aggregation mechanism for GCNs by applying feature-wise Linear Motion which involves applying a transformation to incoming messages.\n","\n","[3] Brockschmidt, M. (2020, November). Gnn-film: Graph neural networks with feature-wise linear modulation. In International Conference on Machine Learning (pp. 1144-1152). PMLR."],"metadata":{"id":"0d2qEJ7fnEhZ"}},{"cell_type":"code","source":["\n","# Create input tensors to pass to the GNN. (Added names to better analyze the output in Model Summary)\n","data = keras.Input(batch_shape=(None,), name = 'data')\n","edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32, name = 'edges')\n","node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32, name = 'n2g')\n","embeded = Embedding(tokenizer.num_words, 20, name = 'emb')(data)\n","\n","\n","# number of graphs (number of samples)\n","num_graph = tf.reduce_max(node2graph)+1\n","\n","# Defining the tuple to pass as an input to the GNN\n","gnn_input = GNNInput(\n","    node_features=embeded,                                        # The initial node features are the input embeddings\n","    adjacency_lists=(edge,),                                      # The adjacency list is teh tensor of edges\n","    node_to_graph_map=node2graph,                                 # Pass the node to graph map\n","    num_graphs=num_graph,                                         # The input works with given no. of samples\n",")\n","\n","\n","params = GNN.get_default_hyperparameters(mp_style='GNN_FiLM')         # Set Message Passing Style = GAT based GCN named as RGAT in the library\n","params[\"hidden_dim\"] = 32\n","gnn_layer = GNN(params)\n","gnn_out = gnn_layer(gnn_input)\n","\n","\n","avg = segment_mean(data=gnn_out, segment_ids=node2graph)          # Calculate the segment mean to use for prediction\n","\n","pred = Dense(1, activation='sigmoid')(avg)                        # Output layer for predictions\n","\n","# Definng the model for training\n","mgfilm = Model(\n","    inputs={\n","        'data': data,\n","        'edges': edge,\n","        'node2graph': node2graph,\n","    },\n","    outputs=pred,\n","    name = \"GCN-FILM\"\n",")\n","mgfilm.summary()\n","\n","# Same as before\n","mgfilm.compile(\n","    optimizer = Adam(learning_rate=0.001, amsgrad = True),\n","    loss='BinaryCrossentropy',\n","    metrics='AUC'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3-7nNJGCnDew","executionInfo":{"status":"ok","timestamp":1670300180244,"user_tz":300,"elapsed":2030,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"9174bcbf-8477-47cd-c959-063c91eda61a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"GCN-FILM\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," n2g (InputLayer)               [(None,)]            0           []                               \n","                                                                                                  \n"," data (InputLayer)              [(None,)]            0           []                               \n","                                                                                                  \n"," tf.math.reduce_max_38 (TFOpLam  ()                  0           ['n2g[0][0]']                    \n"," bda)                                                                                             \n","                                                                                                  \n"," emb (Embedding)                (None, 20)           10000       ['data[0][0]']                   \n","                                                                                                  \n"," edges (InputLayer)             [(None, 2)]          0           []                               \n","                                                                                                  \n"," tf.__operators__.add_38 (TFOpL  ()                  0           ['tf.math.reduce_max_38[0][0]']  \n"," ambda)                                                                                           \n","                                                                                                  \n"," gnn_36 (GNN)                   (None, 32)           30656       ['emb[0][0]',                    \n","                                                                  'edges[0][0]',                  \n","                                                                  'n2g[0][0]',                    \n","                                                                  'tf.__operators__.add_38[0][0]']\n","                                                                                                  \n"," tf.math.segment_mean_30 (TFOpL  (None, 32)          0           ['gnn_36[0][0]',                 \n"," ambda)                                                           'n2g[0][0]']                    \n","                                                                                                  \n"," dense_30 (Dense)               (None, 1)            33          ['tf.math.segment_mean_30[0][0]']\n","                                                                                                  \n","==================================================================================================\n","Total params: 40,689\n","Trainable params: 40,689\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["batch_size = 64                                                                 # Size of inidividual mini-batch (no. of compunds to use for each minibatch)\n","ep = 5                                                                         # No. of Epochs\n","num_batchs = math.ceil(len(training_set) / batch_size)                          # Total no. of batches for training based on total size and size of inidividual mini batch\n","num_batchs_validation = math.ceil(len(validation_set) / batch_size)             # Total no. of batches for validation\n","\n","\n","# Fit the model to begin training\n","mgfilm.fit(\n","    gen_batch(training_set, batch_size=batch_size, repeat=True),                # Generate batches for training based on b_size and passing the training set\n","    steps_per_epoch=num_batchs,                                                 # Each epoch has same steps and the no. of batches\n","    epochs=ep,\n","    validation_data=gen_batch(validation_set, batch_size=16, repeat=True),      # Generate batches for validation\n","    validation_steps=num_batchs_validation,                                     # Steps for validation\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pNiEtHReoUQP","executionInfo":{"status":"ok","timestamp":1670300320547,"user_tz":300,"elapsed":120320,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"11ebccb7-649e-439c-82e8-b6d0f2173403"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_3_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_3_grad/Identity:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/cond_3_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/concat_3:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/concat_2:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/gnn__fi_lm_2/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_1_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_1_grad/Identity:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/cond_1_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_grad/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_1_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_1_grad/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["294/294 [==============================] - 26s 79ms/step - loss: 0.2787 - auc: 0.4623 - val_loss: 0.2088 - val_auc: 0.6879\n","Epoch 2/5\n","294/294 [==============================] - 24s 82ms/step - loss: 0.1933 - auc: 0.6246 - val_loss: 0.1788 - val_auc: 0.7040\n","Epoch 3/5\n","294/294 [==============================] - 23s 80ms/step - loss: 0.1902 - auc: 0.6434 - val_loss: 0.1954 - val_auc: 0.6173\n","Epoch 4/5\n","294/294 [==============================] - 24s 81ms/step - loss: 0.1855 - auc: 0.6810 - val_loss: 0.1767 - val_auc: 0.7262\n","Epoch 5/5\n","294/294 [==============================] - 22s 76ms/step - loss: 0.1835 - auc: 0.6930 - val_loss: 0.1927 - val_auc: 0.7367\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fcfbee44460>"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["# Generate submission from predictions since training results look promising\n","# Predict the labels on testing dataset to find how good the model performs.\n","# y_pred = mgfilm.predict(\n","#     gen_batch(testing_set, batch_size=16, shuffle=False)                     #  Create slices of the Test dataset to generate batches for prediction\n","# )\n","# y_pred = np.reshape(y_pred, -1)                                              # Reshape the data to 1D, also to use for generating csv submissions\n","\n","# submission = pd.DataFrame({'label':y_pred})\n","# submission.index.name = 'id'\n","# submission.to_csv('/content/drive/MyDrive/cisc/A6/S-GF.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WxLCX7C6qO6H","executionInfo":{"status":"ok","timestamp":1670300412570,"user_tz":300,"elapsed":6724,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"998563b1-fee3-4dfa-f68f-4cc8427d2e51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["771/771 [==============================] - 6s 8ms/step\n"]}]},{"cell_type":"markdown","source":["**Observation**:\n","\n","The previous run was really promising and forecasts massive improvements in model performance if the hyperparams are properly tuned."],"metadata":{"id":"jGGpyaXNsP2k"}},{"cell_type":"markdown","source":["## B.\n","\n","\n","The authors suggest using extensive search to find best model params, but I am not sure how to do that.\n","\n","This iteration involves among other things:\n","\n","* Increasing hidden layer for FiLM\n","* Increasing edge MLP layers"],"metadata":{"id":"B0WFyAKuru68"}},{"cell_type":"code","source":["\n","# Create input tensors to pass to the GNN. (Added names to better analyze the output in Model Summary)\n","data = keras.Input(batch_shape=(None,), name = 'data')\n","edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32, name = 'edges')\n","node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32, name = 'n2g')\n","embeded = Embedding(tokenizer.num_words, 20, name = 'emb')(data)\n","\n","\n","# number of graphs (number of samples)\n","num_graph = tf.reduce_max(node2graph)+1\n","\n","# Defining the tuple to pass as an input to the GNN\n","gnn_input = GNNInput(\n","    node_features=embeded,                                        # The initial node features are the input embeddings\n","    adjacency_lists=(edge,),                                      # The adjacency list is teh tensor of edges\n","    node_to_graph_map=node2graph,                                 # Pass the node to graph map\n","    num_graphs=num_graph,                                         # The input works with given no. of samples\n",")\n","\n","\n","params = GNN.get_default_hyperparameters(mp_style='GNN_FiLM')         # Set Message Passing Style = GAT based GCN named as RGAT in the library\n","params[\"hidden_dim\"] = 48\n","params[\"num_layers\"] = 6\n","params[\"layer_input_dropout_rate\"] = 0.25\n","params[\"initial_node_representation_activation\"] = \"relu\"             # Changing activation for node_representation layer\n","params[\"dense_intermediate_layer_activation\"] = \"relu\"                # Changing activation for intermediate layers\n","params[\"num_edge_MLP_hidden_layers\"] = 2                              # FiLM specific MLP hidden layers increased\n","params[\"film_parameter_MLP_hidden_layers\"] = 1                        # Added MLP for FiLM params\n","gnn_layer = GNN(params)\n","gnn_out = gnn_layer(gnn_input)\n","\n","\n","avg = segment_mean(data=gnn_out, segment_ids=node2graph)          # Calculate the segment mean to use for prediction\n","\n","pred = Dense(1, activation='sigmoid')(avg)                        # Output layer for predictions\n","\n","# Definng the model for training\n","mgfilm2 = Model(\n","    inputs={\n","        'data': data,\n","        'edges': edge,\n","        'node2graph': node2graph,\n","    },\n","    outputs=pred,\n","    name = \"GCN-FILM2\"\n",")\n","mgfilm2.summary()\n","\n","# Same as before\n","mgfilm2.compile(\n","    optimizer = Adam(learning_rate=0.001, amsgrad = True),\n","    loss='BinaryCrossentropy',\n","    metrics='AUC'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K4aqQ-QToNhJ","executionInfo":{"status":"ok","timestamp":1670300621306,"user_tz":300,"elapsed":2469,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"25e35422-53a8-4888-e44a-8e79c33d3f0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"GCN-FILM\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," n2g (InputLayer)               [(None,)]            0           []                               \n","                                                                                                  \n"," data (InputLayer)              [(None,)]            0           []                               \n","                                                                                                  \n"," tf.math.reduce_max_41 (TFOpLam  ()                  0           ['n2g[0][0]']                    \n"," bda)                                                                                             \n","                                                                                                  \n"," emb (Embedding)                (None, 20)           10000       ['data[0][0]']                   \n","                                                                                                  \n"," edges (InputLayer)             [(None, 2)]          0           []                               \n","                                                                                                  \n"," tf.__operators__.add_41 (TFOpL  ()                  0           ['tf.math.reduce_max_41[0][0]']  \n"," ambda)                                                                                           \n","                                                                                                  \n"," gnn_39 (GNN)                   (None, 48)           190080      ['emb[0][0]',                    \n","                                                                  'edges[0][0]',                  \n","                                                                  'n2g[0][0]',                    \n","                                                                  'tf.__operators__.add_41[0][0]']\n","                                                                                                  \n"," tf.math.segment_mean_33 (TFOpL  (None, 48)          0           ['gnn_39[0][0]',                 \n"," ambda)                                                           'n2g[0][0]']                    \n","                                                                                                  \n"," dense_33 (Dense)               (None, 1)            49          ['tf.math.segment_mean_33[0][0]']\n","                                                                                                  \n","==================================================================================================\n","Total params: 200,129\n","Trainable params: 200,129\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["batch_size = 64                                                                 # Size of inidividual mini-batch (no. of compunds to use for each minibatch)\n","ep = 5                                                                         # No. of Epochs\n","num_batchs = math.ceil(len(training_set) / batch_size)                          # Total no. of batches for training based on total size and size of inidividual mini batch\n","num_batchs_validation = math.ceil(len(validation_set) / batch_size)             # Total no. of batches for validation\n","\n","\n","# Fit the model to begin training\n","mgfilm2.fit(\n","    gen_batch(training_set, batch_size=batch_size, repeat=True),                # Generate batches for training based on b_size and passing the training set\n","    steps_per_epoch=num_batchs,                                                 # Each epoch has same steps and the no. of batches\n","    epochs=ep,\n","    validation_data=gen_batch(validation_set, batch_size=16, repeat=True),      # Generate batches for validation\n","    validation_steps=num_batchs_validation,                                     # Steps for validation\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FEPs5Sp9rPk6","executionInfo":{"status":"ok","timestamp":1670303166270,"user_tz":300,"elapsed":322153,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"33bf5845-bb80-4e1c-ec7f-9998475762ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","294/294 [==============================] - 61s 209ms/step - loss: 0.1680 - auc: 0.7690 - val_loss: 0.1585 - val_auc: 0.7887\n","Epoch 2/5\n","294/294 [==============================] - 62s 210ms/step - loss: 0.1807 - auc: 0.7511 - val_loss: 0.1811 - val_auc: 0.6993\n","Epoch 3/5\n","294/294 [==============================] - 63s 213ms/step - loss: 0.1716 - auc: 0.7460 - val_loss: 0.1608 - val_auc: 0.7639\n","Epoch 4/5\n","294/294 [==============================] - 61s 208ms/step - loss: 0.1709 - auc: 0.7562 - val_loss: 0.1878 - val_auc: 0.7515\n","Epoch 5/5\n","294/294 [==============================] - 66s 224ms/step - loss: 0.1693 - auc: 0.7599 - val_loss: 0.1620 - val_auc: 0.7792\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fcfb70bd730>"]},"metadata":{},"execution_count":68}]},{"cell_type":"markdown","source":["**Observation**\n","\n","While the AUC score is slightly lesser than that of GAT-2, the val_loss is also really low which sounds promisinng.\n","\n","The trend suggests training for more epochs would yield better results."],"metadata":{"id":"1FQ3pqi7vCtC"}},{"cell_type":"markdown","source":["# Upsampling Data\n","\n"],"metadata":{"id":"-ZsX0wqrvoaG"}},{"cell_type":"markdown","source":["The data is unbalanced, and would benefit from increased positive samples for training.\n","\n","Hence in this block we use the RandomOverSampler to UpSample the minotrity samples and reframe it into the required format for batch generation (as before)"],"metadata":{"id":"5FO8d1iIUxsy"}},{"cell_type":"markdown","source":["## New PreProcessing"],"metadata":{"id":"cIJONd1DOtpS"}},{"cell_type":"code","source":["# Load dataset again in a anew object to prevent overrighting the old one, required for comparison\n","ts2 = read_sdf('/content/drive/MyDrive/cisc/A6/train.sdf')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["01d8b48ba1914d5cb1a85dccab69dbb9","274c6c05b09b4ba8b19b035787ab2c09","fc411c17c73143528a1ce4f729ffd638","6b8ca9e1842945b6a2f122b6d60ee407","f07da8c6fc044c6883c5f71d5d33aa2b","75dc9e24e25e48529807472ca46971ed","faeb430cf96441cf807c7383d9cc28c1","f23fb6ae037a430799a854a827827669","0607cbf51767471e9273e21450bee4bc","f045e61b254741559b7f67d522c512c9","e5d0f54561904a378b0fec3f450e6b02"]},"id":"4yFaL-Et4qxQ","executionInfo":{"status":"ok","timestamp":1670310043838,"user_tz":300,"elapsed":3295,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"9e63f936-7d51-48c1-b979-7d705f7be160"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/25024 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01d8b48ba1914d5cb1a85dccab69dbb9"}},"metadata":{}}]},{"cell_type":"code","source":["# The RandomOverSampler doesn't directly work with graphs or lists containing graph elements.\n","# Hence, the following is required to generate a dataframe for working on the data.\n","# This is just a work around that I found simple to understand, there are other ways to do it.\n","ln = []\n","le = []\n","ll = []\n","for m in ts2:\n","  ln.append(m[0])\n","  le.append(m[1])\n","  ll.append(m[2])\n","\n","frame = pd.DataFrame(list(zip(ln, le, ll)),\n","               columns =['Node', 'Edge', \"labels\"])\n","\n","X = frame.drop(\"labels\", axis = 1)\n","y = frame[\"labels\"]"],"metadata":{"id":"uk1cMHQ59l-E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Upsample Data to increase the number of samples and reduce the large unbalance in the input class\n","\n","from imblearn.over_sampling import RandomOverSampler\n","ros =  RandomOverSampler(sampling_strategy='minority')  # Use the upsampling method to upsample only minority values\n","\n","X_up, y_up = ros.fit_resample(X, y)                     # Fit the UpSampling method on the data X with Y as labels and generate Upsampled set\n","\n","X.shape, y.shape, X_up.shape, y_up.shape                # Show the shape of old data vs new data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZHkG_aXdAVkv","executionInfo":{"status":"ok","timestamp":1670310046179,"user_tz":300,"elapsed":146,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"e13be11d-c71d-4632-a1c3-16eff809ca83"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((25024, 2), (25024,), (47612, 2), (47612,))"]},"metadata":{},"execution_count":166}]},{"cell_type":"code","source":["# Since the data we upsampled is a pandas series type, we need to go back to original form\n","# to be able to use previously defined method on the newly generated dataset\n","\n","# Custom method to fetch elements from series and pass them into the new dataset (list)\n","def assembler(i):\n","  a = X_up[\"Node\"][i]\n","  b = X_up[\"Edge\"][i]\n","  c = y_up[i]\n","  return a, np.array(b), c\n","\n","# Generate list representation of the dataset in the same format as before i.e [nodes, edges, labels]\n","tsnew = []\n","for i in range (len(X_up)):\n","  tsnew.append(assembler(i))"],"metadata":{"id":"scmFWncRDERP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Just a comparison code of the ratio of samples in old dataset vs new dataset\n","# Archaic method to count the elements with positive samples and negative samples and compare the length of list\n","# Its an old spell, but quite effective ;P\n","\n","la = []\n","lb = []\n","for i in training_set:\n","  if i[2] == 1:\n","    la.append(i[2])\n","  else:\n","    lb.append(i[2])\n","\n","print(\"Old class balance= \", len(la), len(lb))\n","\n","for i in tsnew:\n","  if i[2] == 1:\n","    la.append(i[2])\n","  else:\n","    lb.append(i[2])\n","\n","print(\"New class balance= \", len(la), len(lb))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kugwMLCKLvPE","executionInfo":{"status":"ok","timestamp":1670310053063,"user_tz":300,"elapsed":139,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"065d4c28-4b2e-439a-b0d7-a26fd7ad5eb4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Old class balance=  914 17854\n","New class balance=  24720 41660\n"]}]},{"cell_type":"code","source":["# Generate Training and validation sets from new Dataset\n","tset_new, vset_new = train_test_split(tsnew, test_size=0.25,)"],"metadata":{"id":"-pIWKgXxPAHz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_vocab = 500\n","max_len = 100\n","\n","# Build vocabulary from training set\n","all_nodes2 = [s[0] for s in tset_new]      # Get nodes from training set\n","tokenizer2 = Tokenizer(num_words=max_vocab)    # Generate tokens keep a maximum of 500 words, each with a max length of 100\n","tokenizer2.fit_on_texts(all_nodes2)             # Create an index for vocabulary based on frequency of each word/node in the graph"],"metadata":{"id":"DJ2K5vKaPW4X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Implementing the Model Again, with new dataset"],"metadata":{"id":"jCSH4oWNOwoZ"}},{"cell_type":"markdown","source":["Utilizing the GAT-2 model with modified params with the new dataset since it yielded the most stable and high quality result in the previous iterations.\n","\n","This implementation is the same as before, except it is run on the newly generated dataset."],"metadata":{"id":"Nj_oz0npQXSM"}},{"cell_type":"code","source":["\n","# Create input tensors to pass to the GNN. (Added names to better analyze the output in Model Summary)\n","data = keras.Input(batch_shape=(None,), name = 'data')\n","edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32, name = 'edges')\n","node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32, name = 'n2g')\n","embeded = Embedding(tokenizer2.num_words, 20, name = 'emb')(data)\n","\n","\n","# number of graphs (number of samples)\n","num_graph = tf.reduce_max(node2graph)+1\n","\n","# Defining the tuple to pass as an input to the GNN\n","gnn_input = GNNInput(\n","    node_features=embeded,                                        # The initial node features are the input embeddings\n","    adjacency_lists=(edge,),                                      # The adjacency list is teh tensor of edges\n","    node_to_graph_map=node2graph,                                 # Pass the node to graph map\n","    num_graphs=num_graph,                                         # The input works with given no. of samples\n",")\n","\n","\n","params = GNN.get_default_hyperparameters(mp_style='RGAT')         # Set Message Passing Style = GAT based GCN named as RGAT in the library\n","params[\"hidden_dim\"] = 20\n","params[\"num_heads\"] = 4                                           # GAT requires the hidden_dim be a multiple of num_heads. Default = 3\n","params[\"num_layers\"] = 6\n","params[\"layer_input_dropout_rate\"] = 0.25\n","params[\"initial_node_representation_activation\"] = \"relu\"\n","params[\"dense_intermediate_layer_activation\"] = \"relu\"\n","gnn_layer = GNN(params)\n","gnn_out = gnn_layer(gnn_input)\n","\n","\n","avg = segment_mean(data=gnn_out, segment_ids=node2graph)          # Calculate the segment mean to use for prediction\n","\n","pred = Dense(1, activation='sigmoid')(avg)                        # Output layer for predictions\n","\n","# Definng the model for training\n","mgatup = Model(\n","    inputs={\n","        'data': data,\n","        'edges': edge,\n","        'node2graph': node2graph,\n","    },\n","    outputs=pred,\n","    name = \"GATUp-GCN\"\n",")\n","mgatup.summary()\n","\n","# Same as before\n","mgatup.compile(\n","    optimizer = Adam(learning_rate=0.001, amsgrad = True),\n","    loss='BinaryCrossentropy',\n","    metrics='AUC'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"52bfjWb8Ozzo","executionInfo":{"status":"ok","timestamp":1670310422272,"user_tz":300,"elapsed":2034,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"0010e9ec-b339-4808-b656-1b67c81e819c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"GATUp-GCN\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," n2g (InputLayer)               [(None,)]            0           []                               \n","                                                                                                  \n"," data (InputLayer)              [(None,)]            0           []                               \n","                                                                                                  \n"," tf.math.reduce_max_43 (TFOpLam  ()                  0           ['n2g[0][0]']                    \n"," bda)                                                                                             \n","                                                                                                  \n"," emb (Embedding)                (None, 20)           10000       ['data[0][0]']                   \n","                                                                                                  \n"," edges (InputLayer)             [(None, 2)]          0           []                               \n","                                                                                                  \n"," tf.__operators__.add_43 (TFOpL  ()                  0           ['tf.math.reduce_max_43[0][0]']  \n"," ambda)                                                                                           \n","                                                                                                  \n"," gnn_41 (GNN)                   (None, 40)           59360       ['emb[0][0]',                    \n","                                                                  'edges[0][0]',                  \n","                                                                  'n2g[0][0]',                    \n","                                                                  'tf.__operators__.add_43[0][0]']\n","                                                                                                  \n"," tf.math.segment_mean_35 (TFOpL  (None, 40)          0           ['gnn_41[0][0]',                 \n"," ambda)                                                           'n2g[0][0]']                    \n","                                                                                                  \n"," dense_35 (Dense)               (None, 1)            41          ['tf.math.segment_mean_35[0][0]']\n","                                                                                                  \n","==================================================================================================\n","Total params: 69,401\n","Trainable params: 69,401\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["batch_size = 64                                                                 # Size of inidividual mini-batch (no. of compunds to use for each minibatch)\n","ep = 5                                                                         # No. of Epochs\n","num_batchs = math.ceil(len(tset_new) / batch_size)                          # Total no. of batches for training based on total size and size of inidividual mini batch\n","num_batchs_validation = math.ceil(len(vset_new) / batch_size)             # Total no. of batches for validation\n","\n","\n","# Fit the model to begin training\n","mgatup.fit(\n","    gen_batch(tset_new, batch_size=batch_size, repeat=True),                # Generate batches for training based on b_size and passing the training set\n","    steps_per_epoch=num_batchs,                                                 # Each epoch has same steps and the no. of batches\n","    epochs=ep,\n","    validation_data=gen_batch(vset_new, batch_size=16, repeat=True),      # Generate batches for validation\n","    validation_steps=num_batchs_validation,                                     # Steps for validation\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JlcTuzVNQApY","executionInfo":{"status":"ok","timestamp":1670311128030,"user_tz":300,"elapsed":632037,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"90a383e7-565d-4670-ecfb-beb034393b4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_5_grad/gradients/grad_ys_0_indices:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_5_grad/gradients/grad_ys_0_values:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/cond_5_grad/gradients/grad_ys_0_shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_5_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_5_grad/Identity:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/cond_5_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/concat_3:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/concat_2:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/rgat_4/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_3_grad/gradients/grad_ys_0_indices:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_3_grad/gradients/grad_ys_0_values:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/cond_3_grad/gradients/grad_ys_0_shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_3_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_3_grad/Identity:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/cond_3_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/concat_7:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/concat_6:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/rgat_2/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_1_grad/gradients/grad_ys_0_indices:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_1_grad/gradients/grad_ys_0_values:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/cond_1_grad/gradients/grad_ys_0_shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_1_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_1_grad/Identity:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/cond_1_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/rgat/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/rgat/embedding_lookup_grad/Reshape:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/rgat/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/rgat/embedding_lookup_1_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/rgat/embedding_lookup_1_grad/Reshape:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/rgat/embedding_lookup_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["558/558 [==============================] - 141s 235ms/step - loss: 0.6533 - auc: 0.6485 - val_loss: 0.6446 - val_auc: 0.6913\n","Epoch 2/5\n","558/558 [==============================] - 118s 212ms/step - loss: 0.6152 - auc: 0.7124 - val_loss: 0.6108 - val_auc: 0.7460\n","Epoch 3/5\n","558/558 [==============================] - 118s 212ms/step - loss: 0.5972 - auc: 0.7379 - val_loss: 0.5881 - val_auc: 0.7549\n","Epoch 4/5\n","558/558 [==============================] - 125s 224ms/step - loss: 0.5864 - auc: 0.7538 - val_loss: 0.6042 - val_auc: 0.7589\n","Epoch 5/5\n","558/558 [==============================] - 119s 212ms/step - loss: 0.5783 - auc: 0.7645 - val_loss: 0.5636 - val_auc: 0.7962\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fcfc3639ac0>"]},"metadata":{},"execution_count":175}]},{"cell_type":"code","source":["# Generate submission from predictions since training results look promising\n","# Predict the labels on testing dataset to find how good the model performs.\n","y_pred = mgatup.predict(\n","    gen_batch(testing_set, batch_size=16, shuffle=False)                     #  Create slices of the Test dataset to generate batches for prediction\n",")\n","y_pred = np.reshape(y_pred, -1)                                              # Reshape the data to 1D, also to use for generating csv submissions\n","\n","submission = pd.DataFrame({'label':y_pred})\n","submission.index.name = 'id'\n","submission.to_csv('/content/drive/MyDrive/cisc/A6/S-GATUP.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ghsgJlbITeLA","executionInfo":{"status":"ok","timestamp":1670311221575,"user_tz":300,"elapsed":21797,"user":{"displayName":"Tufail Malik","userId":"07100441017475105460"}},"outputId":"e7b511b8-9a36-4660-8b24-2b16cf1ce23a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["771/771 [==============================] - 14s 17ms/step\n"]}]},{"cell_type":"markdown","source":["**Observation**\n","\n","The updsampling clearly boosted the performance by a significant margin as seen on the leaderboard.\n","\n","This result was achieved at just 5 epochs. Calibrating the params more and training for longer would get even better results."],"metadata":{"id":"EqQp4GRzUPZc"}}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"provenance":[{"file_id":"1g-u7AwTQPPquyls6DFWJf2Lb3ImVV-9Q","timestamp":1708459854810}],"collapsed_sections":["wvU-85dBVIfF","uiU40zRZqtwG","AJeCtdi73hxH","GFWO9cA4njJW","YOWy9XqLBLug","JbCzgzgbCBym","P2D8QwvvLH9R","8ueKdBj7POUB","sF5PedDaSKtS","HchvmZVFTBGS","fWJ2iW5OWeOm","Ar4yMyGqbQWo","Ds1c1IbAdnCX","H6zdyVRQiVVo","GcY3sDY2m4K7","0d2qEJ7fnEhZ","B0WFyAKuru68","-ZsX0wqrvoaG","cIJONd1DOtpS","jCSH4oWNOwoZ"]},"widgets":{"application/vnd.jupyter.widget-state+json":{"67b5c79fd0ef422386f0869096cf725f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6c32a8c95d064d4b9f4e7d4f14c7fc8a","IPY_MODEL_5e2f799dd0414635871b41c4ae06b169","IPY_MODEL_2b8846595248472296e337bcdff3f9ad"],"layout":"IPY_MODEL_74fd4c02c5e84558a1b05d48243bdb5c"}},"6c32a8c95d064d4b9f4e7d4f14c7fc8a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f23d59a3fe5d42c0bfae1b1788acfe28","placeholder":"","style":"IPY_MODEL_bb6ecdc5c81047ee8e304c496d4e18de","value":"100%"}},"5e2f799dd0414635871b41c4ae06b169":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_12554cf8294f4a14bea40f2ccc5c6976","max":25024,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0712dbb1cb244156a99422fb381634b1","value":25024}},"2b8846595248472296e337bcdff3f9ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_753ca6691d3c469096e00af80a916099","placeholder":"","style":"IPY_MODEL_68afd771402d4345b0defe9e3619c10a","value":" 25024/25024 [00:03&lt;00:00, 3673.73it/s]"}},"74fd4c02c5e84558a1b05d48243bdb5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f23d59a3fe5d42c0bfae1b1788acfe28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb6ecdc5c81047ee8e304c496d4e18de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12554cf8294f4a14bea40f2ccc5c6976":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0712dbb1cb244156a99422fb381634b1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"753ca6691d3c469096e00af80a916099":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68afd771402d4345b0defe9e3619c10a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"052b94f489b44d0d90b0e55ba021b459":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8378f79672d842049e052210d9ef353a","IPY_MODEL_30a5ed803a1f43c3b940cd87439ef49d","IPY_MODEL_e1388af836ea4cfc96dcd6884482563c"],"layout":"IPY_MODEL_dcf61a7cf590472bb0140efbf88f6b3e"}},"8378f79672d842049e052210d9ef353a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97f2296283724c078bfe34c3aaf097d1","placeholder":"","style":"IPY_MODEL_3d81696172a84c55b40e5ccf6ecc1997","value":"100%"}},"30a5ed803a1f43c3b940cd87439ef49d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_67b82e9e9c8a4e418ae3444117ef429a","max":12326,"min":0,"orientation":"horizontal","style":"IPY_MODEL_72f79c13433a4f558e1a7e2b81d3f18e","value":12326}},"e1388af836ea4cfc96dcd6884482563c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8156b6d2b5534070b6f53a430aa39050","placeholder":"","style":"IPY_MODEL_b74d3b38b50f465fa5b1505bb35cd9c1","value":" 12326/12326 [00:03&lt;00:00, 4129.45it/s]"}},"dcf61a7cf590472bb0140efbf88f6b3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97f2296283724c078bfe34c3aaf097d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d81696172a84c55b40e5ccf6ecc1997":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67b82e9e9c8a4e418ae3444117ef429a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72f79c13433a4f558e1a7e2b81d3f18e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8156b6d2b5534070b6f53a430aa39050":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b74d3b38b50f465fa5b1505bb35cd9c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"01d8b48ba1914d5cb1a85dccab69dbb9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_274c6c05b09b4ba8b19b035787ab2c09","IPY_MODEL_fc411c17c73143528a1ce4f729ffd638","IPY_MODEL_6b8ca9e1842945b6a2f122b6d60ee407"],"layout":"IPY_MODEL_f07da8c6fc044c6883c5f71d5d33aa2b"}},"274c6c05b09b4ba8b19b035787ab2c09":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75dc9e24e25e48529807472ca46971ed","placeholder":"","style":"IPY_MODEL_faeb430cf96441cf807c7383d9cc28c1","value":"100%"}},"fc411c17c73143528a1ce4f729ffd638":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f23fb6ae037a430799a854a827827669","max":25024,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0607cbf51767471e9273e21450bee4bc","value":25024}},"6b8ca9e1842945b6a2f122b6d60ee407":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f045e61b254741559b7f67d522c512c9","placeholder":"","style":"IPY_MODEL_e5d0f54561904a378b0fec3f450e6b02","value":" 25024/25024 [00:02&lt;00:00, 9998.42it/s]"}},"f07da8c6fc044c6883c5f71d5d33aa2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75dc9e24e25e48529807472ca46971ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"faeb430cf96441cf807c7383d9cc28c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f23fb6ae037a430799a854a827827669":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0607cbf51767471e9273e21450bee4bc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f045e61b254741559b7f67d522c512c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5d0f54561904a378b0fec3f450e6b02":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}